/*@

abstract_type type_info;

@*/

mod verifast {

    // Used to translate Rust array literals of the form &[V1, V2, V3]
    fn produce_const_ref<T>() -> &'static T;
    //@ req thread_token(?t);
    //@ ens thread_token(t) &*& <&'static T>.own(t, result) &*& [_]ref_initialized(result);
    //@ on_unwind_ens false;

}

mod hint {

    fn assert_unchecked(b: bool);
    //@ req b;
    //@ ens true;
    //@ on_unwind_ens false;

}

mod ops {

    trait FnOnce<Args> {

        type Output;
    
        fn call_once(self: Self, args: Args) -> <Self as std::ops::FnOnce<Args>>::Output;
        //@ req thread_token(?t) &*& <Self>.own(t, self) &*& <Args>.own(t, args);
        //@ ens thread_token(t) &*& < <Self as std::ops::FnOnce<Args>>::Output>.own(t, result);
        //@ on_unwind_ens thread_token(t);
        
    }

    trait FnMut<Args> {
    
        fn call_mut<'a>(self: &'a mut Self, args: Args) -> <Self as std::ops::FnOnce<Args>>::Output;
        //@ req thread_token(?t) &*& *self |-> ?self0 &*& <Self>.own(t, self0) &*& <Args>.own(t, args);
        //@ ens thread_token(t) &*& *self |-> ?self1 &*& <Self>.own(t, self1) &*& < <Self as std::ops::FnOnce<Args>>::Output>.own(t, result);
        //@ on_unwind_ens thread_token(t) &*& *self |-> ?self1 &*& <Self>.own(t, self1);
        
    }
    
    trait Fn<Args> {
    
        fn call<'a>(self: &'a Self, args: Args) -> <Self as std::ops::FnOnce<Args>>::Output;
        //@ req thread_token(?t) &*& [?q]lifetime_token('a) &*& [_](<Self>.share('a, t, self)) &*& <Args>.own(t, args);
        //@ ens thread_token(t) &*& [q]lifetime_token('a) &*& < <Self as std::ops::FnOnce<Args>>::Output>.own(t, result);
        //@ on_unwind_ens thread_token(t) &*& [q]lifetime_token('a);
        
    }
    
    struct Range<Idx> {
        start: Idx,
        end: Idx,
    }
    
    impl std::iter::IntoIterator for std::ops::Range<usize> {
    
        fn into_iter(self: Range<usize>) -> Range<usize>;
        //@ req true;
        //@ ens result == self;
        //@ on_unwind_ens false;
    
    }
    
    impl std::iter::Iterator for std::ops::Range<usize> {
    
        fn next<'a>(self: &'a mut Range<usize>) -> std::option::Option<usize>;
        //@ req *self |-> ?self0;
        /*@
        ens if self0.start < self0.end {
                *self |-> Range::<usize> { start: self0.start + 1, end: self0.end } &*& result == std::option::Option::Some(self0.start)
            } else {
                *self |-> self0 &*& result == std::option::Option::None
            };
        @*/
        //@ on_unwind_ens false;
        
    }
    
    enum ControlFlow<B, C> {
        Continue(C),
        Break(B)
    }
    
}

mod rt {

    fn begin_panic<M>(msg: M); // Generated by the assert! macro
    //@ req true; // TODO: Express that the message is valid.
    //@ ens false;
    //@ on_unwind_ens true;

}

mod cmp {

    enum Ordering {
        Less,
        Equal,
        Greater,
    }
    
    impl<T> for T = usize {
    
        fn max<T>(self: usize, other: usize) -> usize;
        //@ req true;
        //@ ens result == if self < other { other } else { self };
        //@ on_unwind_ens false;

    }        

}

mod num {

    impl u32 {
    
        fn checked_add(self: u32, other: u32) -> std::option::Option<u32>;
        //@ req true;
        //@ ens if self + other <= u32::MAX { result == std::option::Option::Some(self + other) } else { result == std::option::Option::None };
        //@ on_unwind_ens false;
        
    }

    impl u64 {
    
        fn wrapping_add(self: u64, other: u64) -> u64;
        //@ req true;
        //@ ens true;
        //@ on_unwind_ens false;
        
        fn wrapping_mul(self: u64, other: u64) -> u64;
        //@ req true;
        //@ ens true;
        //@ on_unwind_ens false;
        
    }

    /*@
    
    lem init_ref_usize(p: *usize, coef: real);
        req ref_init_perm::<usize>(p, ?x) &*& [?f](*x |-> ?v) &*& 0 < coef &*& coef < 1;
        ens ref_initialized(p) &*& [coef*f](*p |-> v) &*& [(1 - coef)*f](*x |-> v) &*& ref_end_token(p, x, coef*f);
    
    lem end_ref_usize(p: *usize);
        req ref_initialized(p) &*& ref_end_token(p, ?x, ?f) &*& [f](*p |-> ?v);
        ens [f](*x |-> v);
    
    fix wrapping_sub_usize(a: usize, b: usize) -> usize { if b <= a { a - b } else { a + usize::MAX + 1 - b } }
    
    @*/

    impl usize {
    
        fn checked_sub(self: usize, other: usize) -> std::option::Option<usize>;
        //@ req true;
        //@ ens if self < other { result == std::option::Option::None } else { result == std::option::Option::Some(self - other) };
        //@ on_unwind_ens false;

        fn checked_add(self: usize, other: usize) -> std::option::Option<usize>;
        //@ req true;
        //@ ens if self + other > usize::MAX { result == std::option::Option::None } else { result == std::option::Option::Some(self + other) };
        //@ on_unwind_ens false;
        
        fn unchecked_mul(self: usize, other: usize) -> usize;
        //@ req self * other <= usize::MAX;
        //@ ens result == self * other;
        //@ on_unwind_ens false;
        
        fn wrapping_sub(self: usize, other: usize) -> usize;
        //@ req true;
        //@ ens result == wrapping_sub_usize(self, other);
        //@ on_unwind_ens false;
        
    }
    
    impl std::cmp::Ord for usize {
    
        fn cmp<'a>(self: &'a usize, other: &'a usize) -> std::cmp::Ordering;
        //@ req [?fs](*self |-> ?vself) &*& [?fo](*other |-> ?vother);
        //@ ens [fs](*self |-> vself) &*& [fo](*other |-> vother) &*& result == (if vself < vother { std::cmp::Ordering::Less } else if vself == vother { std::cmp::Ordering::Equal } else { std::cmp::Ordering::Greater });
        //@ on_unwind_ens false;
    
        fn max(self: usize, other: usize) -> usize;
        //@ req true;
        //@ ens result == if self < other { other } else { self };
        //@ on_unwind_ens false;
    
    }
    
    mod niche_types {
    
        struct UsizeNoHighBit;
        
        //@ fix UsizeNoHighBit::new(n: usize) -> UsizeNoHighBit;
        //@ fix UsizeNoHighBit::as_inner(n: UsizeNoHighBit) -> usize;
        
        /*@
        
        lem close_UsizeNoHighBit_own(t: thread_id_t, self_: UsizeNoHighBit);
            req true;
            ens <UsizeNoHighBit>.own(t, self_);
        
        lem_auto(UsizeNoHighBit::new(n).as_inner()) UsizeNoHighBit_as_inner_new(n: usize);
            req 0 <= n && n <= isize::MAX;
            ens UsizeNoHighBit::new(n).as_inner() == n;
        
        lem_auto(UsizeNoHighBit::as_inner(transmute_uint(n))) UsizeNoHighBit_as_inner_transmute_uint(n: usize);
            req 0 <= n && n <= isize::MAX;
            ens UsizeNoHighBit::as_inner(transmute_uint(n)) == n;
        
        lem_auto transmute_uint_UsizeNoHighBit(n: usize);
            req 0 <= n && n <= isize::MAX;
            ens transmute_uint::<UsizeNoHighBit>(n) == UsizeNoHighBit::new(n);
        
        lem UsizeNoHighBit_inv(n: UsizeNoHighBit);
            req true;
            ens 0 <= n.as_inner() &*& n.as_inner() <= isize::MAX;
        
        pred end_ref_UsizeNoHighBit_token(p: *UsizeNoHighBit, x: *UsizeNoHighBit, f: real);
        
        lem init_ref_UsizeNoHighBit(p: *UsizeNoHighBit, coef: real);
            req ref_init_perm(p, ?x) &*& [?f](*x |-> ?u) &*& 0 < coef &*& coef < 1;
            ens end_ref_UsizeNoHighBit_token(p, x, f*coef) &*& [(1-coef)*f](*x |-> u) &*& [coef*f](*p |-> u) &*& ref_initialized(p);
        
        lem end_ref_UsizeNoHighBit(p: *UsizeNoHighBit);
            req end_ref_UsizeNoHighBit_token(p, ?x, ?f) &*& [f](*p |-> ?u) &*& ref_initialized(p);
            ens [f](*x |-> u);
        
        @*/
        
        impl UsizeNoHighBit {
        
            fn as_inner(self: UsizeNoHighBit) -> usize;
            //@ req true;
            //@ ens result == self.as_inner();
            //@ on_unwind_ens false;
            
            fn new_unchecked(value: usize) -> UsizeNoHighBit;
            //@ req value <= isize::MAX;
            //@ ens result == UsizeNoHighBit::new(value);
            //@ on_unwind_ens false;
            
        }
    
    }
    
    struct NonZero<T>;
    
    //@ fix NonZero::get<T>(nz: NonZero<T>) -> T;
    
    /*@
    
    lem NonZero_usize_limits(nz: NonZero<usize>);
        req true;
        ens 0 < nz.get() &*& nz.get() <= usize::MAX;
    
    @*/

}

mod marker {

    struct PhantomData<T> {}
    
    /*@
    
    lem close_PhantomData_own<T>(t: thread_id_t, marker: PhantomData<T>);
        req true;
        ens <PhantomData<T>>.own(t, marker);
    
    lem close_ref_initialized_PhantomData<T>(marker: *PhantomData<T>, f: real);
        req true;
        ens [f]ref_initialized::<PhantomData<T>>(marker);
    
    @*/
    
}

mod intrinsics {

    fn ub_checks() -> bool;
    //@ req true;
    //@ ens result == false; // TODO: Also check the case where `ub_checks()` returns `true`. https://github.com/verifast/verifast/issues/931
    //@ on_unwind_ens false;

    unsafe fn ptr_offset_from<T>(ptr: *const T, base: *const T) -> isize;
    /*@
    req
        (ptr as pointer).provenance == (base as pointer).provenance &*&
        (ptr as usize - base as usize) % std::mem::size_of::<T>() == 0 &*&
        isize::MIN <= ptr as usize - base as usize &*& ptr as usize - base as usize <= isize::MAX;
    @*/
    //@ ens result == ptr as usize - base as usize;
    //@ on_unwind_ens false;
    
    // atomic_points_to(p, v) is like points_to(p, v) but additionally, it guarantees that place *p is not accessed
    // with non-read-only mixed-size accesses since converting from points_to to atomic_points_to is possible only
    // at top mask, which means the conversion can be thought of as happening in a separate machine step.
    // Furthermore, it guarantees that p is properly aligned for atomic accesses at type T.
    
    // Note: these specs are sufficient to prove semantic well-typedness of the sync::atomic API, but are not
    // sufficient to prove arbitrary functional correctness properties. TODO: Extend these specs to also support the latter.
    
    /*@
    
    fix atomic_align_of<T>() -> usize;
    
    lem_auto atomic_align_of_u8();
        req true;
        ens atomic_align_of::<u8>() == 1;
    
    lem_auto atomic_align_of_usize();
        req true;
        ens atomic_align_of::<usize>() == std::mem::size_of::<usize>();
    
    pred atomic_points_to<T>(p: *T, frac: real, inv_: fix(T, bool););
    
    lem close_atomic_points_to_m<T>(p: *T, inv_: fix(T, bool));
        req atomic_mask(MaskTop) &*& [?f](*p |-> ?v) &*& p as usize % atomic_align_of::<T>() == 0 &*& inv_(v) == true;
        ens atomic_mask(MaskTop) &*& atomic_points_to(p, f, inv_);
    
    lem open_atomic_points_to<T>(p: *T);
        req atomic_points_to(p, ?f, ?inv_);
        ens [f](*p |-> ?v) &*& inv_(v) == true;
    
    @*/
    
    unsafe fn atomic_store_relaxed<T>(dst: *mut T, val: T);
    //@ req [?f]atomic_points_to(dst, 1, ?inv_) &*& inv_(val) == true;
    //@ ens [f]atomic_points_to(dst, 1, inv_);
    //@ on_unwind_ens false;
    
    unsafe fn atomic_store_release<T>(dst: *mut T, val: T);
    //@ req [?f]atomic_points_to(dst, 1, ?inv_) &*& inv_(val) == true;
    //@ ens [f]atomic_points_to(dst, 1, inv_);
    //@ on_unwind_ens false;
    
    unsafe fn atomic_store_seqcst<T>(dst: *mut T, val: T);
    //@ req [?f]atomic_points_to(dst, 1, ?inv_) &*& inv_(val) == true;
    //@ ens [f]atomic_points_to(dst, 1, inv_);
    //@ on_unwind_ens false;
    
}

mod mem {

    fn size_of<T>() -> usize;
    //@ req true;
    //@ ens result == std::mem::size_of::<T>();
    //@ on_unwind_ens false;
    
    fn IS_ZST<T>() -> bool; // The VeriFast MIR translator translates T::IS_ZST unevaluated constants to IS_ZST::<T>() calls.
    //@ req true;
    //@ ens result == (std::mem::size_of::<T>() == 0);
    //@ on_unwind_ens false;
    
    fn align_of<T>() -> usize;
    //@ req true;
    //@ ens result == std::mem::align_of::<T>();
    //@ on_unwind_ens false;

    fn drop<T>(value: T);
    //@ req thread_token(?t) &*& <T>.own(t, value);
    //@ ens thread_token(t);
    //@ on_unwind_ens thread_token(t);
    
    fn forget<T>(value: T);
    //@ req thread_token(?t) &*& <T>.own(t, value);
    //@ ens thread_token(t);
    //@ on_unwind_ens false;
    
    fn replace<T, 'a>(dest: &'a mut T, src: T) -> T;
    //@ req *dest |-> ?v;
    //@ ens *dest |-> src &*& result == v;
    //@ on_unwind_ens false;
    
    struct MaybeUninit<T>;
    
    /*@
    
    fix MaybeUninit::inner<T>(v: MaybeUninit<T>) -> option<T>;
    fix MaybeUninit::new<T>(v: T) -> MaybeUninit<T>;
    fix MaybeUninit::uninit<T>() -> MaybeUninit<T>;
    fix MaybeUninit::new_maybe_uninit<T>(v: option<T>) -> MaybeUninit<T>;
    
    lem_auto MaybeUninit_inner_new<T>(v: T);
        req true;
        ens MaybeUninit::new(v).inner() == some(v);
    
    lem_auto MaybeUninit_inner_new_maybe_uninit<T>(v: option<T>);
        req true;
        ens MaybeUninit::new_maybe_uninit(v).inner() == v;
    
    lem open_MaybeUninit<T>(self: *MaybeUninit<T>);
        req *self |-> ?value;
        ens *(self as *T) |-?-> value.inner();
    
    lem close_MaybeUninit_<T>(self: *MaybeUninit<T>);
        req *(self as *T) |-?-> ?value;
        ens *self |-> MaybeUninit::new_maybe_uninit(value);
        
    lem close_MaybeUninit<T>(self: *MaybeUninit<T>);
        req *(self as *T) |-> ?value;
        ens *self |-> MaybeUninit::new(value);
    
    lem open_MaybeUninit_<T>(self: *MaybeUninit<T>);
        req *self |-?-> ?value;
        ens *(self as *T) |-?-> match value { none => none, some(value_) => value_.inner() };
    
    lem MaybeUninit__to_MaybeUninit<T>(self: *MaybeUninit<T>);
        req *self |-?-> ?value;
        ens *self |-> match value { none => MaybeUninit::uninit(), some(value_) => value_ };
    
    lem Array__MaybeUninit_to_Array_MaybeUninit<T, N>(self: *[MaybeUninit<T>; N]);
        req *self |-?-> ?value_;
        ens *self |-> match value_ { none => Array_of_elems(repeat(nat_of_int(usize_of_const(typeid(N))), MaybeUninit::uninit())), some(value) => value };
    
    lem array__MaybeUninit_to_array_MaybeUninit<T>(self: *MaybeUninit<T>);
        req self[..?n] |-?-> ?elems_;
        ens self[..n] |-> map((unwrap_or_else)(MaybeUninit::uninit), elems_);
    
    lem array__to_array_MaybeUninit<T>(self: *T);
        req self[..?n] |-?-> ?elems_;
        ens (self as *MaybeUninit<T>)[..n] |-> map(MaybeUninit::new_maybe_uninit, elems_);
    
    lem array_at_lft__to_array_at_lft_MaybeUninit<T>(self: *T);
        req array_at_lft_(?k, self, ?n, ?elems_);
        ens array_at_lft(k, self as *MaybeUninit<T>, n, map(MaybeUninit::new_maybe_uninit, elems_));
    
    lem_auto(std::mem::size_of::<MaybeUninit<T>>()) size_of_MaybeUninit<T>();
        req true;
        ens std::mem::size_of::<MaybeUninit<T>>() == std::mem::size_of::<T>();
    
    lem_auto(std::mem::align_of::<MaybeUninit<T>>()) align_of_MaybeUninit<T>();
        req true;
        ens std::mem::align_of::<MaybeUninit<T>>() == std::mem::align_of::<T>();
    
    @*/
    
    impl<T> MaybeUninit<T> {
    
        fn write<'a>(self: &'a mut MaybeUninit<T>, value: T) -> &'a mut T;
        //@ req *self |-> _;
        //@ ens *self |-> MaybeUninit::new(value);
        //@ on_unwind_ens false;
        
    }
    
    mod verifast {
    
        fn unfreeze<T>(ptr: *T);
        //@ req [1/2](*ptr |-> ?v);
        //@ ens *ptr |-> v;
        //@ on_unwind_ens false;
        
        fn freeze<T>(ptr: *T);
        //@ req *ptr |-> _;
        //@ ens [1/2](*ptr |-> _);
        //@ on_unwind_ens false;
    
    }
    
}

mod ptr {

    unsafe fn copy<T>(src: *mut T, dst: *mut T, count: usize);
    /*@
    req src[..count] |-> ?vs &*&
        if src <= dst {
            ((src + count) as *u8)[..dst as *u8 - src as *u8] |-> _
        } else {
            (dst as *u8)[..src as *u8 - dst as *u8] |-> _
        };
    @*/
    /*@
    ens dst[..count] |-> vs &*&
        if src <= dst {
            (src as *u8)[..dst as *u8 - src as *u8] |-> _
        } else {
            ((dst + count) as *u8)[..src as *u8 - dst as *u8] |-> _
        };
    @*/
    //@ on_unwind_ens false;
    //@ terminates;

    unsafe fn copy_nonoverlapping<T>(src: *mut T, dst: *mut T, count: usize);
    //@ req [?f]src[..count] |-> ?vs &*& dst[..count] |-> _;
    //@ ens [f]src[..count] |-> vs &*& dst[..count] |-> vs;
    //@ on_unwind_ens false;
    //@ terminates;
    
    unsafe fn write_bytes<T>(dst: *mut T, val: u8, count: usize);
    //@ req dst[..count] |-> _ &*& (dst as usize % std::mem::align_of::<T>()) == 0;
    //@ ens (dst as *u8)[..count * std::mem::size_of::<T>()] |-> repeat(nat_of_int(count * std::mem::size_of::<T>()), val);
    //@ on_unwind_ens false;
    //@ terminates;

    fn without_provenance_mut<T>(addr: usize) -> *mut T;
    //@ req true;
    //@ ens result == addr as *T;
    
    fn slice_from_raw_parts_mut<T>(data: *T, len: usize) -> slice_ptr<T>;
    //@ req true;
    //@ ens result == slice_ptr::<T> { ptr: data, len };
    //@ on_unwind_ens false;

    unsafe fn drop_in_place<T>(to_drop: *mut T);
    //@ req thread_token(?t) &*& *to_drop |-> ?v &*& <T>.own(t, v);
    //@ ens thread_token(t) &*& *to_drop |-> _;
    //@ on_unwind_ens thread_token(t) &*& *to_drop |-> _;

    struct NonNull<T>;
    
    /*@
    
    fix NonNull::without_provenance<T>(addr: std::num::NonZero<usize>) -> NonNull<T>;
    
    lem_auto(NonNull::without_provenance::<T>(addr).as_ptr()) NonNull_as_ptr_NonNull_without_provenance<T>(addr: std::num::NonZero<usize>);
        req true;
        ens NonNull::without_provenance::<T>(addr).as_ptr() == addr.get() as *T;
    
    lem close_NonNull_own<T>(t: thread_id_t, v: NonNull<T>);
        req true;
        ens (NonNull_own::<T>())(t, v);
        
    lem open_NonNull_own<T>(t: thread_id_t, v: NonNull<T>);
        req [_](NonNull_own::<T>())(t, v);
        ens v.as_ptr() as usize != 0;
        
    fix NonNull::as_ptr<T>(v: NonNull<T>) -> *T;
    
    // If ptr is 0, the result of NonNull::new_ is unspecified. (It is never the case that NonNull_ptr(nnp) == 0.)
    fix NonNull::new<T>(ptr: *T) -> NonNull<T>;
    
    lem_auto(NonNull::new(ptr).as_ptr()) NonNull_as_ptr_new<T>(ptr: *T);
        req ptr != 0 && pointer_within_limits(ptr);
        ens NonNull::new(ptr).as_ptr() == ptr;
    
    lem NonNull_new_as_ptr<T>(v: NonNull<T>);
        req true;
        ens NonNull::new(v.as_ptr()) == v;
    
    lem_auto(v.as_ptr()) NonNull_as_ptr_nonnull<T>(v: NonNull<T>);
        req true;
        ens v.as_ptr() != 0 && pointer_within_limits(v.as_ptr());
    
    lem NonNull_upcast<T0, T1>(v: NonNull<T0>);
        req true;
        ens NonNull::as_ptr::<T1>(upcast(v)) == NonNull::as_ptr::<T0>(v) as *_;
    
    lem init_ref_NonNull<T>(p: *NonNull<T>, coef: real);
        req ref_init_perm(p, ?x) &*& [?f](*x |-> ?v) &*& 0 < coef &*& coef < 1;
        ens ref_initialized(p) &*& [(1 - coef)*f](*x |-> v) &*& [coef*f](*p |-> v) &*& ref_end_token(p, x, coef*f);
    
    lem end_ref_NonNull<T>(p: *NonNull<T>);
        req ref_initialized(p) &*& ref_end_token(p, ?x, ?f) &*& [f](*p |-> ?v);
        ens [f](*x |-> v);
    
    @*/

    impl<T> NonNull<T> {
        fn without_provenance(addr: std::num::NonZero<usize>) -> NonNull<T>;
        //@ req true;
        //@ ens result == NonNull::without_provenance(addr);
        //@ on_unwind_ens false;
        
        unsafe fn new_unchecked(ptr: *mut T) -> NonNull<T>;
        //@ req ptr as usize != 0;
        //@ ens result.as_ptr() == ptr;
        //@ on_unwind_ens false;
        
        unsafe fn as_mut<'a, 'b>(self: &'b mut NonNull<T>) -> &'a mut T;
        //@ req *self |-> ?v;
        //@ ens *self |-> v &*& result == v.as_ptr();
        //@ on_unwind_ens false;

        unsafe fn as_ref<'a, 'b>(self: &'b NonNull<T>) -> &'a T;
        //@ req [?q](*self) |-> ?v;
        //@ ens [q](*self) |-> v &*& result == v.as_ptr();
        //@ on_unwind_ens false;

        fn as_ptr(self: NonNull<T>) -> *mut T;
        //@ req true;
        //@ ens result == self.as_ptr();
        //@ on_unwind_ens false;
        
        fn cast<U>(self: NonNull<T>) -> NonNull<U>;
        //@ req true;
        //@ ens result == NonNull::new(self.as_ptr() as *U);
        
        fn cast_slice<U>(self: NonNull_slice0<T>) -> NonNull<U>;
        //@ req true;
        //@ ens result == NonNull::new(self.ptr.as_ptr() as *U);
        
    }
    
    struct NonNull_slice0<T> { // Used by the MIR translator to represent NoNull<[T]> types
        ptr: std::ptr::NonNull<T>,
        len: usize,
    }
    
    struct Unique<T>;
    
    //@ fix Unique::from_non_null<T>(nn: NonNull<T>) -> Unique<T>;
    //@ fix Unique::as_non_null_ptr<T>(u: Unique<T>) -> NonNull<T>;
    
    /*@
    
    lem close_Unique_own<T>(t: thread_id_t, self_: Unique<T>);
        req true;
        ens <Unique<T>>.own(t, self_);
    
    lem_auto(Unique::from_non_null(nn).as_non_null_ptr()) Unique_as_non_null_ptr_from_non_null<T>(nn: NonNull<T>);
        req true;
        ens Unique::from_non_null(nn).as_non_null_ptr() == nn;
    
    pred end_ref_Unique_token<T>(p: *Unique<T>, x: *Unique<T>, f: real);
    
    lem init_ref_Unique<T>(p: *Unique<T>, coef: real);
        req ref_init_perm(p, ?x) &*& [?f](*x |-> ?u) &*& 0 < coef &*& coef < 1;
        ens end_ref_Unique_token(p, x, f*coef) &*& [(1-coef)*f](*x |-> u) &*& [coef*f](*p |-> u) &*& ref_initialized(p);
    
    lem end_ref_Unique<T>(p: *Unique<T>);
        req end_ref_Unique_token(p, ?x, ?f) &*& [f](*p |-> ?u) &*& ref_initialized(p);
        ens [f](*x |-> u);
    
    @*/
    
    impl<T> Unique<T> {
    
        fn from_non_null(ptr: NonNull<T>) -> Unique<T>;
        //@ req true;
        //@ ens result == Unique::from_non_null(ptr);
        //@ on_unwind_ens false;
        
        fn as_non_null_ptr(self: Unique<T>) -> NonNull<T>;
        //@ req true;
        //@ ens result == self.as_non_null_ptr();
        //@ on_unwind_ens false;
        
        fn new_unchecked(ptr: *mut T) -> Unique<T>;
        //@ req ptr != 0;
        //@ ens result == Unique::from_non_null(NonNull::new(ptr));
        //@ on_unwind_ens false;
        
        fn cast<U>(self: Unique<T>) -> Unique<U>;
        //@ req true;
        //@ ens result == Unique::from_non_null(NonNull::new(self.as_non_null_ptr().as_ptr() as *U));
        //@ on_unwind_ens false;
        
    }
    
    impl<T> std::convert::Into<std::ptr::NonNull<T>> for std::ptr::Unique<T> {
    
        fn into(self: Unique<T>) -> NonNull<T>;
        //@ req true;
        //@ ens result == self.as_non_null_ptr();
        //@ on_unwind_ens false;
        
    }
    
    impl<T> std::convert::From<std::ptr::NonNull<T>> for std::ptr::Unique<T> {
    
        fn from(value: NonNull<T>) -> Unique<T>;
        //@ req true;
        //@ ens result == Unique::from_non_null(value) &*& result.as_non_null_ptr() == value;
        //@ on_unwind_ens false;
    
    }
    
    struct Alignment;
    
    //@ fix Alignment::as_nonzero(align: Alignment) -> std::num::NonZero<usize>;
    //@ fix Alignment::new(align: usize) -> Alignment;
    
    /*@
    
    lem Alignment_as_nonzero_new(align: usize);
        req is_power_of_2(align) == true;
        ens Alignment::new(align).as_nonzero().get() == align;
    
    lem Alignment_is_power_of_2(align: Alignment);
        req true;
        ens is_power_of_2(align.as_nonzero().get()) == true;
    
    @*/
    
    impl Alignment {
    
        fn as_nonzero(self: Alignment) -> std::num::NonZero<usize>;
        //@ req true;
        //@ ens result == self.as_nonzero();
        //@ on_unwind_ens false;
        
        fn of<T>() -> Alignment;
        //@ req true;
        //@ ens result == Alignment::new(std::mem::align_of::<T>());
        //@ on_unwind_ens false;
        
    }
    
}

mod slice {

    struct Iter<'a, T>;
    
    struct IterMut<'a, T>;

}

mod str {

    struct Chars<'a>;
    
    struct Utf8Error;

}

mod cell {

    struct Cell<T>;

}

mod alloc {

    struct Layout;
    
    /*@
    
    lem close_Layout_own(t: thread_id_t, l: Layout);
        req true;
        ens <Layout>.own(t, l);
    
    @*/
    
    //@ fix Layout::size(layout: Layout) -> usize;
    //@ fix Layout::align(layout: Layout) -> usize;
    //@ fix Layout::from_size_align(size: usize, align: usize) -> Layout;
    //@ fix Layout::new<T>() -> Layout { Layout::from_size_align(std::mem::size_of::<T>(), std::mem::align_of::<T>()) }
    //@ fix Layout::repeat(layout: Layout, n: usize) -> option<pair<Layout, usize>>;
    
    //@ fix is_valid_layout(size: usize, align: usize) -> bool { is_power_of_2(align) && 0 <= size && size <= isize::MAX - isize::MAX % align }
    //@ fix Layout::is_valid(layout: Layout) -> bool { is_valid_layout(layout.size(), layout.align()) }
    
    /*@
    
    lem_auto Layout_size_Layout_from_size_align(size: usize, align: usize);
        req is_valid_layout(size, align) == true;
        ens Layout::from_size_align(size, align).size() == size;
    
    lem_auto Layout_align_Layout_from_size_align(size: usize, align: usize);
        req is_valid_layout(size, align) == true;
        ens Layout::from_size_align(size, align).align() == align;
    
    lem Layout_inv(layout: Layout);
        req true;
        ens is_valid_layout(layout.size(), layout.align()) == true;
    
    lem_auto is_valid_layout_size_of_align_of<T>();
        req true;
        ens is_valid_layout(std::mem::size_of::<T>(), std::mem::align_of::<T>()) == true;
    
    lem_auto Layout_is_valid_new<T>();
        req true;
        ens Layout::is_valid(Layout::new::<T>()) == true;
    
    lem_auto(Layout::from_size_align(l.size(), l.align())) Layout_from_size_align_Layout_size_Layout_align(l: Layout);
        req true;
        ens Layout::from_size_align(l.size(), l.align()) == l;
    
    lem Layout_repeat_some(layout: Layout, n: usize);
        req layout.repeat(n) == some(pair(?result, ?stride));
        ens layout.size() <= stride &*&
            stride % layout.align() == 0 &*&
            stride - layout.size() < layout.align() &*&
            result.size() == n * stride &*&
            result.align() == layout.align();
    
    lem Layout_repeat_some_size_aligned(layout: Layout, n: usize);
        req layout.repeat(n) == some(pair(?result, ?stride)) &*& layout.size() % layout.align() == 0;
        ens result.size() == n * layout.size() &*&
            result.align() == layout.align() &*&
            stride == layout.size();
    
    lem Layout_repeat_size_aligned_intro(layout: Layout, n: usize);
        req layout.size() % layout.align() == 0 &*& 0 <= n &*& n * layout.size() <= isize::MAX;
        ens layout.repeat(n) == some(pair(?result, layout.size())) &*&
            result.size() == n * layout.size() &*&
            result.align() == layout.align();
    
    pred end_ref_Layout_token(p: *Layout, x: *Layout, f: real);
    
    lem init_ref_Layout(p: *Layout, coef: real);
        req ref_init_perm(p, ?x) &*& [?f](*x |-> ?l) &*& 0 < coef &*& coef < 1;
        ens end_ref_Layout_token(p, x, coef*f) &*& [(1-coef)*f](*x |-> l) &*& [coef*f](*p |-> l) &*& ref_initialized(p);
    
    lem end_ref_Layout(p: *Layout);
        req end_ref_Layout_token(p, ?x, ?f) &*& [f](*p |-> ?l) &*& ref_initialized(p);
        ens [f](*x |-> l);
    
    @*/
    
    struct LayoutError;
    
    impl Layout {
    
        fn new<T>() -> Layout;
        //@ req true;
        //@ ens result == Layout::new::<T>();
        //@ on_unwind_ens false;

        fn from_size_align_unchecked(size: usize, align: usize) -> Layout;
        //@ req is_power_of_2(align) == true && size <= isize::MAX - isize::MAX % align;
        //@ ens result == Layout::from_size_align(size, align) &*& result.size() == size &*& result.align() == align;
        //@ on_unwind_ens false;
        
        fn size<'a>(self: &'a Layout) -> usize;
        //@ req [?f](*self |-> ?l);
        //@ ens [f](*self |-> l) &*& result == l.size();
        //@ on_unwind_ens false;

        fn align<'a>(self: &'a Layout) -> usize;
        //@ req [?f](*self |-> ?l);
        //@ ens [f](*self |-> l) &*& result == l.align() &*& is_power_of_2(result) == true;
        //@ on_unwind_ens false;
        
        fn alignment<'a>(self: &'a Layout) -> std::ptr::Alignment;
        //@ req [?f](*self |-> ?l);
        //@ ens [f](*self |-> l) &*& result == std::ptr::Alignment::new(l.align()) &*& result.as_nonzero().get() == l.align();

        fn repeat<'a>(self: &'a Layout, n: usize) -> std::result::Result<(Layout, usize), LayoutError>;
        //@ req [?f](*self |-> ?l);
        /*@
        ens [f](*self |-> l) &*&
            match result {
                Result::Ok(r) =>
                    l.repeat(n) == some(pair(r.0, r.1)) &*&
                    r.0.size() == n * r.1 &*&
                    l.size() <= r.1 &*&
                    r.1 % l.align() == 0 &*&
                    r.1 - l.size() < l.align() &*&
                    r.0.align() == l.align(),
                Result::Err(e) => true
            };
        @*/
        //@ on_unwind_ens false;
        
    }
    
    //@ pred alloc_block(ptr: *u8; layout: Layout);
    
    //@ inductive alloc_id_t = alloc_id(id: any, lft: lifetime_t);
    
    //@ pred alloc_block_in(alloc_id: alloc_id_t, ptr: *u8, layout: Layout;);
    
    /*@
    
    lem alloc_aligned(ptr: *mut u8);
        req [?f]alloc_block(ptr, ?layout);
        ens [f]alloc_block(ptr, layout) &*& (ptr as usize) % layout.align() == 0 &*& ref_origin(ptr) == ptr;
    
    lem alloc_block_in_aligned(ptr: *mut u8);
        req [?f]alloc_block_in(?alloc_id, ptr, ?layout);
        ens [f]alloc_block_in(alloc_id, ptr, layout) &*& (ptr as usize) % layout.align() == 0 &*& ref_origin(ptr) == ptr;
    
    @*/
    
    /*@
    
    pred Allocator<A>(t: thread_id_t, alloc: A, alloc_id: alloc_id_t);
    pred Allocator_share<A>(k: lifetime_t, t: thread_id_t, l: *A, alloc_id: alloc_id_t);
    
    lem Allocator_upcast<A0, A1>(alloc: A0);
        req Allocator::<A0>(?t, alloc, ?alloc_id) &*& is_subtype_of::<A0, A1>() == true;
        ens Allocator::<A1>(t, upcast(alloc), alloc_id);
    
    lem Allocator_send<A>(t1: thread_id_t, alloc: A);
        req type_interp::<A>() &*& Allocator::<A>(?t0, alloc, ?alloc_id) &*& is_Send(typeid(A)) == true;
        ens type_interp::<A>() &*& Allocator::<A>(t1, alloc, alloc_id);
    
    lem Allocator_to_own<A>(alloc: A);
        req Allocator::<A>(?t, alloc, _);
        ens <A>.own(t, alloc);
    
    lem open_Allocator_own<A>(alloc: A);
        req <A>.own(?t, alloc);
        ens Allocator::<A>(t, alloc, _);
    
    fix Allocator_full_borrow_content_<A>(t: thread_id_t, l: *A, alloc_id: alloc_id_t) -> pred();
    
    lem close_Allocator_full_borrow_content_<A>(t: thread_id_t, l: *A);
        req *l |-> ?alloc &*& Allocator::<A>(t, alloc, ?alloc_id);
        ens (Allocator_full_borrow_content_::<A>(t, l, alloc_id))();
    
    lem open_Allocator_full_borrow_content_<A>(t: thread_id_t, l: *A, alloc_id: alloc_id_t);
        req (Allocator_full_borrow_content_::<A>(t, l, alloc_id))();
        ens *l |-> ?alloc &*& Allocator::<A>(t, alloc, alloc_id);
    
    lem share_Allocator_full_borrow_content_<A>(k: lifetime_t, t: thread_id_t, l: *A, alloc_id: alloc_id_t);
        nonghost_callers_only
        req full_borrow(k, Allocator_full_borrow_content_::<A>(t, l, alloc_id)) &*& [?q]lifetime_token(k);
        ens [_]Allocator_share(k, t, l, alloc_id) &*& [q]lifetime_token(k);
    
    lem share_Allocator_full_borrow_content_m<A>(k: lifetime_t, t: thread_id_t, l: *A, alloc_id: alloc_id_t);
        req type_interp::<A>() &*& atomic_mask(MaskTop) &*& full_borrow(k, Allocator_full_borrow_content_::<A>(t, l, alloc_id)) &*& [?q]lifetime_token(k);
        ens type_interp::<A>() &*& atomic_mask(MaskTop) &*& [_]Allocator_share(k, t, l, alloc_id) &*& [q]lifetime_token(k);
    
    lem Allocator_share_mono<A>(k: lifetime_t, k1: lifetime_t, t: thread_id_t, l: *A);
        req type_interp::<A>() &*& [_]Allocator_share(k, t, l, ?alloc_id) &*& lifetime_inclusion(k1, k) == true;
        ens type_interp::<A>() &*& [_]Allocator_share(k1, t, l, alloc_id);
    
    lem Allocator_sync<A>(t1: thread_id_t);
        req type_interp::<A>() &*& is_Sync(typeid(A)) == true &*& [_]Allocator_share::<A>(?k, ?t0, ?l, ?alloc_id);
        ens type_interp::<A>() &*& [_]Allocator_share::<A>(k, t1, l, alloc_id);
    
    lem close_Allocator_share<A>(k: lifetime_t, t: thread_id_t, l: *A);
        req [_]Allocator_share(k, t, l, _);
        ens [_](<A>.share(k, t, l));
    
    lem init_ref_Allocator_share<A>(k: lifetime_t, t: thread_id_t, p: *A);
        nonghost_callers_only
        req ref_init_perm(p, ?x) &*& [_]Allocator_share(k, t, x, ?allocId) &*& [?q]lifetime_token(k);
        ens [q]lifetime_token(k) &*& [_]Allocator_share(k, t, p, allocId) &*& [_]frac_borrow(k, ref_initialized_(p));
    
    lem init_ref_Allocator_share_m<A>(k: lifetime_t, t: thread_id_t, p: *A);
        req type_interp::<A>() &*& atomic_mask(Nlft) &*& ref_init_perm(p, ?x) &*& [_]Allocator_share(k, t, x, ?allocId) &*& [?q]lifetime_token(k);
        ens type_interp::<A>() &*& atomic_mask(Nlft) &*& [q]lifetime_token(k) &*& [_]Allocator_share(k, t, p, allocId) &*& [_]frac_borrow(k, ref_initialized_(p));
    
    lem close_Allocator_ref<'a, A>(t: thread_id_t, l: *A);
        req [_]Allocator_share('a, t, l, ?alloc_id);
        ens Allocator::<&'a A>(t, l, alloc_id);
    
    pred share_allocator_at_lifetime_end_token<A>(t: thread_id_t, l: *A, alloc_id: alloc_id_t, k: lifetime_t);
    
    lem share_allocator_at_lifetime<'a, A>(l: *A);
        nonghost_callers_only
        req *l |-> ?alloc &*& Allocator(?t, alloc, ?alloc_id);
        ens Allocator::<&'a A>(t, l, alloc_id) &*& share_allocator_at_lifetime_end_token(t, l, alloc_id, 'a);
    
    lem end_share_allocator_at_lifetime<A>();
        nonghost_callers_only
        req share_allocator_at_lifetime_end_token::<A>(?t, ?l, ?alloc_id, ?k) &*& [_]lifetime_dead_token(k);
        ens *l |-> ?alloc &*& Allocator::<A>(t, alloc, alloc_id);
    
    pred ref_Allocator_end_token_at_lifetime<A>(t: thread_id_t, p: *A, x: *A, alloc_id: alloc_id_t, k: lifetime_t);
    
    lem init_ref_Allocator_at_lifetime<'a, A>(p: *A);
        nonghost_callers_only
        req ref_init_perm(p, ?x) &*& *x |-> ?alloc &*& Allocator(?t, alloc, ?alloc_id);
        ens ref_initialized(p) &*& Allocator::<&'a A>(t, p, alloc_id) &*& ref_Allocator_end_token_at_lifetime(t, p, x, alloc_id, 'a);
    
    lem end_ref_Allocator_at_lifetime<A>();
        nonghost_callers_only
        req ref_Allocator_end_token_at_lifetime::<A>(?t, ?p, ?x, ?alloc_id, ?k) &*& [_]lifetime_dead_token(k) &*& ref_initialized(p);
        ens *x |-> ?alloc &*& Allocator::<A>(t, alloc, alloc_id);
    
    @*/

    fn alloc(layout: Layout) -> *u8;
    //@ req 1 <= layout.size();
    /*@
    ens
        if result == 0 {
            true
        } else {
            ref_origin(result) == result &*&
            result[..layout.size()] |-> _ &*& alloc_block(result, layout) &*&
            result as usize % layout.align() == 0 &*&
            object_pointer_within_limits(result, layout.size()) == true
        };
    @*/
    //@ on_unwind_ens true;
    //@ terminates;
    
    fn realloc(buffer: *u8, layout: Layout, new_size: usize) -> *u8;
    //@ req buffer[..?len] |-> ?vs1 &*& buffer[len..layout.size()] |-?-> ?vs2 &*& alloc_block(buffer, layout) &*& layout.size() <= new_size;
    /*@
    ens
        if result == 0 {
            buffer[..len] |-> vs1 &*& buffer[len..layout.size()] |-?-> vs2 &*& alloc_block(buffer, layout)
        } else {
            result[..len] |-> vs1 &*& result[len..layout.size()] |-?-> vs2 &*&
            result[layout.size()..new_size] |-> _ &*& alloc_block(result, Layout::from_size_align(new_size, layout.align()))
        };
    @*/
    //@ on_unwind_ens true;
    
    fn dealloc(p: *u8, layout: Layout);
    //@ req alloc_block(p, layout) &*& p[..layout.size()] |-> _;
    //@ ens true;
    //@ on_unwind_ens true;
    //@ terminates;
    
    fn handle_alloc_error(layout: Layout);
    //@ req true;
    //@ ens false;
    //@ on_unwind_ens true;
    //@ terminates;
    
    struct Global {}
    
    struct AllocError {}
    
    /*@
    
    fix Global_alloc_id() -> alloc_id_t;
    
    lem produce_Allocator_Global(t: thread_id_t);
        req true;
        ens Allocator(t, Global {}, Global_alloc_id);
    
    @*/
    
    trait Allocator {
    
        // Note: for simplicity, this spec for fn `allocate` does not provide access to the extra bytes (at `ptr[layout.size()..]`).
        // Our use case (RawVec) does not use these extra bytes anyway.
        // TODO: Provide access to the extra bytes (probably by introducing a predicate `alloc_block_in_(alloc_id, ptr, requested_layout, actual_length)`
        // and defining `alloc_block_in(alloc_id, ptr, layout) = alloc_block_in_(alloc_id, ptr, layout, ?len) &*& ptr[layout.size()..len] |-> _`).
    
        fn allocate<'a>(self: &'a Self, layout: Layout) -> std::result::Result<std::ptr::NonNull_slice0<u8>, AllocError>;
        //@ req thread_token(?t) &*& Allocator::<&'a Self>(t, self, ?alloc_id);
        /*@
        ens thread_token(t) &*& Allocator::<&'a Self>(t, self, alloc_id) &*& 
            match result {
                Result::Ok(ptr) =>
                    alloc_block_in(alloc_id, ptr.ptr.as_ptr(), layout) &*&
                    array_at_lft_(alloc_id.lft, ptr.ptr.as_ptr(), layout.size(), _) &*&
                    layout.size() <= ptr.len &*&
                    is_valid_layout(ptr.len, layout.align()) == true,
                Result::Err(e) => true
            };
        @*/
        //@ on_unwind_ens thread_token(t) &*& Allocator::<&'a Self>(t, self, alloc_id);
    
        fn allocate_zeroed<'a>(self: &'a Self, layout: Layout) -> std::result::Result<std::ptr::NonNull_slice0<u8>, AllocError>;
        //@ req thread_token(?t) &*& Allocator::<&'a Self>(t, self, ?alloc_id);
        /*@
        ens thread_token(t) &*& Allocator::<&'a Self>(t, self, alloc_id) &*& 
            match result {
                Result::Ok(ptr) =>
                    alloc_block_in(alloc_id, ptr.ptr.as_ptr(), layout) &*&
                    array_at_lft(alloc_id.lft, ptr.ptr.as_ptr(), layout.size(), ?bs) &*& forall(bs, (eq)(0)) == true &*&
                    layout.size() <= ptr.len &*&
                    is_valid_layout(ptr.len, layout.align()) == true,
                Result::Err(e) => true
            };
        @*/
        //@ on_unwind_ens thread_token(t) &*& Allocator::<&'a Self>(t, self, alloc_id);
    
        unsafe fn deallocate<'a>(self: &'a Self, ptr: std::ptr::NonNull<u8>, layout: Layout);
        //@ req thread_token(?t) &*& Allocator::<&'a Self>(t, self, ?alloc_id) &*& alloc_block_in(alloc_id, ptr.as_ptr(), layout) &*& array_at_lft_(alloc_id.lft, ptr.as_ptr(), layout.size(), _);
        //@ ens thread_token(t) &*& Allocator::<&'a Self>(t, self, alloc_id);
        //@ on_unwind_ens thread_token(t) &*& Allocator::<&'a Self>(t, self, alloc_id);
        
        unsafe fn grow<'a>(self: &'a Self, ptr: std::ptr::NonNull<u8>, old_layout: Layout, new_layout: Layout) -> std::result::Result<std::ptr::NonNull_slice0<u8>, AllocError>;
        /*@
        req thread_token(?t) &*&
            Allocator::<&'a Self>(t, self, ?alloc_id) &*&
            alloc_block_in(alloc_id, ptr.as_ptr(), old_layout) &*&
            array_at_lft_(alloc_id.lft, ptr.as_ptr(), old_layout.size(), ?bs) &*&
            old_layout.size() <= new_layout.size();
        @*/
        /*@
        ens thread_token(t) &*& Allocator::<&'a Self>(t, self, alloc_id) &*& 
            match result {
                Result::Ok(new_ptr) =>
                    alloc_block_in(alloc_id, new_ptr.ptr.as_ptr(), new_layout) &*&
                    array_at_lft_(alloc_id.lft, new_ptr.ptr.as_ptr(), new_layout.size(), _) &*&
                    new_layout.size() <= new_ptr.len &*&
                    is_valid_layout(new_ptr.len, new_layout.align()) == true,
                Result::Err(e) =>
                    alloc_block_in(alloc_id, ptr.as_ptr(), old_layout) &*&
                    array_at_lft_(alloc_id.lft, ptr.as_ptr(), old_layout.size(), bs)
            };
        @*/
        //@ on_unwind_ens thread_token(t) &*& Allocator::<&'a Self>(t, self, alloc_id);
        
        unsafe fn shrink<'a>(self: &'a Self, ptr: std::ptr::NonNull<u8>, old_layout: Layout, new_layout: Layout) -> std::result::Result<std::ptr::NonNull_slice0<u8>, AllocError>;
        /*@
        req thread_token(?t) &*&
            Allocator::<&'a Self>(t, self, ?alloc_id) &*&
            alloc_block_in(alloc_id, ptr.as_ptr(), old_layout) &*&
            array_at_lft_(alloc_id.lft, ptr.as_ptr(), old_layout.size(), ?bs) &*&
            new_layout.size() <= old_layout.size();
        @*/
        /*@
        ens thread_token(t) &*& Allocator::<&'a Self>(t, self, alloc_id) &*& 
            match result {
                Result::Ok(new_ptr) =>
                    alloc_block_in(alloc_id, new_ptr.ptr.as_ptr(), new_layout) &*&
                    array_at_lft_(alloc_id.lft, new_ptr.ptr.as_ptr(), new_layout.size(), _) &*&
                    new_layout.size() <= new_ptr.len &*&
                    is_valid_layout(new_ptr.len, new_layout.align()) == true,
                Result::Err(e) =>
                    alloc_block_in(alloc_id, ptr.as_ptr(), old_layout) &*&
                    array_at_lft_(alloc_id.lft, ptr.as_ptr(), old_layout.size(), bs)
            };
        @*/
        //@ on_unwind_ens thread_token(t) &*& Allocator::<&'a Self>(t, self, alloc_id);
        
    }
    
}

mod boxed {

    struct Box<T, A>;
    struct Box_slice0<T, A>; // The VeriFast MIR translator translates Box<[T], A> to Box_slice0<T, A>
    
    /*@
    
    pred Box<T>(self: Box<T, std::alloc::Global>, value: T);
    
    lem Box_to_own<T>(self: Box<T, std::alloc::Global>);
        req thread_token(?t) &*& Box::<T>(self, ?value) &*& <T>.own(t, value);
        ens thread_token(t) &*& <Box<T, std::alloc::Global>>.own(t, self);
    
    pred Box_in<T, A>(t: thread_id_t, self: Box<T, A>, alloc_id: std::alloc::alloc_id_t, value: T);
    pred Box_slice_in<T, A>(t: thread_id_t, self: Box_slice0<T, A>, alloc_id: std::alloc::alloc_id_t, values: list<T>);
    
    lem own_to_Box_in<T, A>(self: Box<T, A>);
        req <Box<T, A>>.own(?t, self);
        ens Box_in::<T, A>(t, self, ?alloc_id, ?value) &*& <T>.own(t, value);
    
    lem Box_in_to_own<T, A>(self: Box<T, A>);
        req Box_in::<T, A>(?t, self, ?alloc_id, ?value) &*& <T>.own(t, value);
        ens <Box<T, A>>.own(t, self);
    
    @*/
    
    /*@
    
    // This takes a pointer to a Box because moving the Box invalidates the pointer to the contents! https://github.com/verifast/verifast/issues/685#issuecomment-2626864223
    pred Box_minus_contents_in<T, A>(boxFrac: real, t: thread_id_t, placeFrac: real, self: *Box<T, A>, alloc_id: std::alloc::alloc_id_t; contents_ptr: *T);
    
    lem Box_separate_contents<T, A>(self: *Box<T, A>) -> *T;
        req [?fs](*self |-> ?self0) &*& [?f]Box_in::<T, A>(?t, self0, ?alloc_id, ?value);
        ens Box_minus_contents_in(f, t, fs, self, alloc_id, result) &*& [f]points_to_at_lft(alloc_id.lft, result, value);
    
    lem Box_unseparate_contents<T, A>(self: *Box<T, A>);
        req Box_minus_contents_in(?f, ?t, ?fs, self, ?alloc_id, ?contents_ptr) &*& [f]points_to_at_lft(alloc_id.lft, contents_ptr, ?value);
        ens [fs](*self |-> ?self1) &*& [f]Box_in(t, self1, alloc_id, value);
    
    @*/
    
    /*@
    
    pred init_ref_Box_in_token<T, A>(t: thread_id_t, p: *Box<T, A>, fs: real, x: *Box<T, A>, alloc_id: std::alloc::alloc_id_t, p_contents_ptr: *T, x_contents_ptr: *T, f: real);
    
    lem open_ref_init_perm_Box_in<T, A>(p: *Box<T, A>) -> *T;
        req ref_init_perm::<Box<T, A>>(p, ?x) &*& Box_minus_contents_in::<T, A>(?f, ?t, ?fs, x, ?alloc_id, ?x_contents_ptr);
        ens init_ref_Box_in_token::<T, A>(t, p, fs, x, alloc_id, result, x_contents_ptr, f) &*& ref_init_perm::<T>(result, x_contents_ptr);
    
    lem init_ref_Box_in<T, A>(p: *Box<T, A>, coef: real);
        req init_ref_Box_in_token::<T, A>(?t, p, ?fs, ?x, ?alloc_id, ?p_contents_ptr, ?x_contents_ptr, ?f) &*& ref_initialized::<T>(p_contents_ptr) &*& 0 < coef &*& coef < 1;
        ens ref_initialized::<Box<T, A>>(p) &*& Box_minus_contents_in::<T, A>((1-coef)*f, t, (1-coef)*fs, x, alloc_id, x_contents_ptr) &*& Box_minus_contents_in::<T, A>(coef*f, t, coef*fs, p, alloc_id, p_contents_ptr) &*& ref_end_token(p, x, coef*f);
    
    lem end_ref_Box_in<T, A>(p: *Box<T, A>);
        req ref_initialized::<Box<T, A>>(p) &*& ref_end_token(p, ?x, ?f) &*& Box_minus_contents_in::<T, A>(f, ?t, ?fs, p, ?alloc_id, ?p_contents_ptr);
        ens Box_minus_contents_in::<T, A>(f, t, fs, x, alloc_id, _) &*& ref_initialized::<T>(p_contents_ptr);
    
    @*/

    impl<T> Box<T> {
    
        fn new(x: T) -> Box<T, std::alloc::Global>;
        //@ req thread_token(?t) &*& drop_perm::<T>(?charged, ?R, t, x);
        //@ ens thread_token(t) &*& Box(result, x) &*& drop_perm::<T>(charged, R, t, x);
        //@ on_unwind_ens thread_token(t);
        
        fn from_raw(x: *T) -> Box<T, std::alloc::Global>;
        //@ req *x |-> ?value &*& std::alloc::alloc_block(x as *u8, std::alloc::Layout::new::<T>());
        //@ ens Box(result, value);
        //@ on_unwind_ens false;
        
        fn into_raw(b: Box<T, std::alloc::Global>) -> *T;
        //@ req Box(b, ?value);
        //@ ens *result |-> value &*& std::alloc::alloc_block(result as *u8, std::alloc::Layout::new::<T>()) &*& result as usize != 0;
        //@ on_unwind_ens false;
        
    }
    
    impl<T, A> Box<T, A> {
    
        fn new_in(x: T, alloc: A) -> Box<T, A>;
        //@ req thread_token(?t) &*& std::alloc::Allocator(t, alloc, ?alloc_id) &*& drop_perm::<T>(?charged, ?R, t, x);
        //@ ens thread_token(t) &*& Box_in(t, result, alloc_id, x) &*& drop_perm::<T>(charged, R, t, x);
        //@ on_unwind_ens thread_token(t);
        
        fn from_raw_in(x: *T, alloc: A) -> Box<T, A>;
        //@ req std::alloc::Allocator(?t, alloc, ?alloc_id) &*& std::alloc::alloc_block_in(alloc_id, x as *u8, std::alloc::Layout::new::<T>()) &*& points_to_at_lft(alloc_id.lft, x, ?value);
        //@ ens Box_in(t, result, alloc_id, value);
        //@ on_unwind_ens false;
    
        fn from_raw_slice_in(x: slice_ptr<T>, alloc: A) -> Box_slice0<T, A>;
        //@ req std::alloc::Allocator(?t, alloc, ?alloc_id) &*& array_at_lft(alloc_id.lft, x.ptr, x.len, ?vs) &*& if x.len * std::mem::size_of::<T>() == 0 { true } else { std::alloc::alloc_block_in(alloc_id, x.ptr as *u8, std::alloc::Layout::from_size_align(x.len * std::mem::size_of::<T>(), std::mem::align_of::<T>())) };
        //@ ens Box_slice_in(t, result, alloc_id, vs);
        //@ on_unwind_ens false;
    
        fn into_inner(b: Box<T, A>) -> T;
        //@ req thread_token(?t) &*& Box_in::<T, A>(t, b, ?alloc_id, ?value);
        //@ ens thread_token(t) &*& result == value;
        //@ on_unwind_ens thread_token(t);
    
        fn leak<'a>(b: Box<T, A>) -> &'a mut T;
        //@ req Box_in::<T, A>(?t, b, ?alloc_id, ?value);
        //@ ens points_to_at_lft(alloc_id.lft, result, value) &*& std::alloc::alloc_block_in(alloc_id, result as *u8, std::alloc::Layout::new::<T>()) &*& result as *_ as usize != 0;
        //@ on_unwind_ens false;
    
        fn new_uninit_in(alloc: A) -> Box<std::mem::MaybeUninit<T>, A>;
        //@ req thread_token(?t) &*& std::alloc::Allocator(t, alloc, ?alloc_id);
        //@ ens thread_token(t) &*& Box_in(t, result, alloc_id, _);
        //@ on_unwind_ens thread_token(t);
        
        fn as_mut_ptr<'a>(self: &'a mut Box<T, A>) -> *mut T;
        //@ req Box_minus_contents_in(?f, ?t, ?fs, self, ?alloc_id, ?contents_ptr);
        //@ ens Box_minus_contents_in(f, t, fs, self, alloc_id, contents_ptr) &*& result == contents_ptr;
        
    }
    
    impl<T, A> Box<std::mem::MaybeUninit<T>, A> {

        fn assume_init(b: Box<std::mem::MaybeUninit<T>, A>) -> Box<T, A>;
        //@ req Box_in(?t, b, ?alloc_id, ?value) &*& std::mem::MaybeUninit::inner(value) == some(?value_);
        //@ ens Box_in(t, result, alloc_id, value_);

    }

}

mod process {
    fn abort();
    //@ req true;
    //@ ens false;
    //@ on_unwind_ens false;
    //@ terminates;

    fn exit(code: i32);
    //@ req true;
    //@ ens false;
    //@ on_unwind_ens false;
    //@ terminates;
}
//Todo @Nima: Edit Rust parser so it substitutes `!` type with std_empty_ union

mod option {

    enum Option<T> {
        None,
        Some(T),
    }
    
    /*@
    
    fix Option_Some_0_offset<T>() -> usize;
    fix Option_Some_0_ptr<T>(ptr: *Option<T>) -> *T { field_ptr(ptr as pointer, typeid(T), Option_Some_0_offset::<T>()) as *T }
    
    pred Option_Some<T>(l: *Option<T>;); // Represents ownership of the discriminant
    
    lem open_points_to_Option_Some<T>(l: *Option<T>);
        req [?f](*l |-> Option::Some(?v0));
        ens [f]Option_Some(l) &*& [f](*Option_Some_0_ptr(l) |-> v0);
    
    lem close_points_to_Option_Some<T>(l: *Option<T>);
        req [?f]Option_Some(l) &*& [f](*Option_Some_0_ptr(l) |-> ?v0);
        ens [f](*l |-> Option::Some(v0));
    
    lem init_ref_Option_None<T>(p: *Option<T>, coef: real);
        req ref_init_perm::<Option<T>>(p, ?x) &*& [?f](*x |-> Option::None) &*& 0 < coef &*& coef < 1;
        ens ref_initialized::<Option<T>>(p) &*& ref_end_token(p, x, coef*f) &*& [(1-coef)*f](*x |-> Option::None) &*& [coef*f](*p |-> Option::None);
    
    pred init_ref_Option_Some_token<T>(p: *Option<T>, x: *Option<T>, frac: real);
    
    lem open_ref_init_perm_Option_Some<T>(p: *Option<T>);
        req ref_init_perm::<Option<T>>(p, ?x) &*& [?f]Option_Some::<T>(x);
        ens init_ref_Option_Some_token::<T>(p, x, f) &*& ref_init_perm::<T>(Option_Some_0_ptr(p), Option_Some_0_ptr(x));
    
    lem init_ref_Option_Some<T>(p: *Option<T>, coef: real);
        req init_ref_Option_Some_token::<T>(p, ?x, ?f) &*& ref_initialized::<T>(Option_Some_0_ptr(p)) &*& 0 < coef &*& coef < 1;
        ens ref_initialized::<Option<T>>(p) &*& [(1-coef)*f]Option_Some::<T>(x) &*& [coef*f]Option_Some::<T>(p) &*& ref_end_token(p, x, coef*f);
    
    lem end_ref_Option_None<T>(p: *Option<T>);
        req ref_initialized::<Option<T>>(p) &*& ref_end_token(p, ?x, ?f) &*& [f](*p |-> Option::None);
        ens [f](*x |-> Option::None);
    
    lem end_ref_Option_Some<T>(p: *Option<T>);
        req ref_initialized::<Option<T>>(p) &*& ref_end_token(p, ?x, ?f) &*& [f]Option_Some::<T>(p);
        ens [f]Option_Some::<T>(x) &*& ref_initialized::<T>(Option_Some_0_ptr(p));
    
    @*/
    
    impl<T> Option<T> {
    
        fn is_some<'a>(self: &'a Option<T>) -> bool;
        //@ req [?f](*self |-> ?v);
        //@ ens [f](*self |-> v) &*& result == (v != Option::None);
        //@ on_unwind_ens false;
        
        fn take<'a>(self: &'a mut Option<T>) -> Option<T>;
        //@ req *self |-> ?v;
        //@ ens *self |-> Option::None &*& result == v;
        //@ on_unwind_ens false;
        
        fn unwrap_or(self: Option<T>, default: T) -> T;
        //@ req true;
        //@ ens result == match self { Option::None => default, Option::Some(v) => v };
        //@ on_unwind_ens false;
        
        fn unwrap_unchecked(self: Option<T>) -> T;
        //@ req self == Option::Some(?v);
        //@ ens result == v;
        //@ on_unwind_ens false;
        
        fn ok_or<E>(self: Option<T>, err: E) -> std::result::Result<T, E>;
        //@ req true;
        //@ ens result == match self { Option::None => std::result::Result::Err(err), Option::Some(v) => std::result::Result::Ok(v) };
        //@ on_unwind_ens false;
        
        fn unwrap(self: Option<T>) -> T;
        //@ req true;
        //@ ens self == Option::Some(result);
        //@ on_unwind_ens self == Option::None;
        
    }
    
    impl<T> std::ops::Try for std::option::Option<T> {
    
        fn branch(self: Option<T>) -> std::ops::ControlFlow<Option<std::convert::Infallible>, T>;
        //@ req true;
        /*@
        ens match self {
                Option::None => result == std::ops::ControlFlow::Break(Option::None),
                Option::Some(v) => result == std::ops::ControlFlow::Continue(v)
            };
        @*/
        //@ on_unwind_ens false;
    
    }
    
    impl<T> std::ops::FromResidual<std::option::Option<std::convert::Infallible>> for std::option::Option<T> {
    
        fn from_residual(residual: Option<std::convert::Infallible>) -> Option<T>;
        //@ req true;
        //@ ens result == Option::None;
        //@ on_unwind_ens false;
        
    }

}

mod result {

    enum Result<T, E> {
        Ok(T),
        Err(E),
    }
    
    impl<T, E> Result<T, E> {
    
        fn unwrap(self: Result<T, E>) -> T;
        /*@
        req thread_token(?t) &*&
            match self {
                Result::Ok(r) => ens thread_token(t) &*& result == r,
                Result::Err(err) => <E>.own(t, err) &*& ens false
            };
        @*/
        //@ ens true;
        //@ on_unwind_ens thread_token(t);
    
    }

    impl<T, E> std::ops::Try for std::result::Result<T, E> {
    
        fn branch(self: Result<T, E>) -> std::ops::ControlFlow<Result<std::convert::Infallible, E>, T>;
        //@ req true;
        /*@
        ens match self {
                Result::Ok(v) => result == std::ops::ControlFlow::Continue(v),
                Result::Err(e) => result == std::ops::ControlFlow::Break(Result::Err(e))
            };
        @*/
        //@ on_unwind_ens false;
    
    }
    
    impl<T, E> std::ops::FromResidual<std::result::Result<std::convert::Infallible, E>> for std::result::Result<T, E> {
    
        fn from_residual(residual: Result<std::convert::Infallible, E>) -> Result<T, E>;
        //@ req true;
        //@ ens match residual { Result::Ok(v) => result == Result::Err(default_value::<E>), Result::Err(e) => result == Result::Err(e) };
        //@ on_unwind_ens false;
        
    }

}

mod collections {

    struct TryReserveError;
    
    enum TryReserveErrorKind {
        CapacityOverflow,
        AllocError {
            layout: std::alloc::Layout,
            non_exhaustive: ()
        }
    }
    
    impl TryReserveError {
    
        fn kind<'a>(self: &'a TryReserveError) -> TryReserveErrorKind;
        //@ req [?f](*self |-> ?err); // NOTE: This assumes that TryReserveError has no UnsafeCell inside.
        //@ ens [f](*self |-> err);
        //@ on_unwind_ens false;
        
    }
    
    impl<T> std::ops::FromResidual<std::result::Result<std::convert::Infallible, std::collections::TryReserveErrorKind>> for std::result::Result<T, std::collections::TryReserveError> {
    
        fn from_residual(residual: std::result::Result<std::convert::Infallible, TryReserveErrorKind>) -> std::result::Result<T, TryReserveError>;
        //@ req residual == std::result::Result::Err(?e0) &*& <TryReserveErrorKind>.own(?t, e0);
        //@ ens result == std::result::Result::Err(?e1) &*& <TryReserveError>.own(t, e1);
        //@ on_unwind_ens false;

    }
    
}

mod vec {

    struct Vec<T, A>;
    
    //@ pred Vec<T, A>(self: Vec<T, A>, capacity: usize, elems: list<T>); // This predicate does *not* assert ownership of the elements.
    //@ pred Vec_minus_buffer<T, A>(self: Vec<T, A>, capacity: usize, len: usize, buffer: *T);
    
    /*@
    
    lem_auto Vec_inv<T, A>();
        req [?f]Vec::<T, A>(?vec, ?capacity, ?elems);
        ens [f]Vec::<T, A>(vec, capacity, elems) &*& length(elems) <= capacity &*& capacity <= isize::MAX;
    
    lem Vec_separate_buffer<T, A>(self: Vec<T, A>) -> *T;
        req [?f]Vec::<T, A>(self, ?capacity, ?elems);
        ens [f]Vec_minus_buffer::<T, A>(self, capacity, length(elems), result) &*& [f]result[..length(elems)] |-> elems &*& [f]result[length(elems)..capacity] |-> _;
    
    lem Vec_unseparate_buffer<T, A>(self: Vec<T, A>);
        req [?f]Vec_minus_buffer::<T, A>(self, ?capacity, ?len, ?buffer) &*& [f]buffer[..len] |-> ?elems &*& [f]buffer[len..capacity] |-> _;
        ens [f]Vec::<T, A>(self, capacity, elems);
    
    lem Vec_to_own<T, A>(self: Vec<T, A>);
        req thread_token(?t) &*& Vec::<T, A>(self, ?capacity, ?elems) &*& foreach(elems, own::<T>(t));
        ens thread_token(t) &*& <Vec<T, A>>.own(t, self);
    
    lem own_to_Vec<T, A>(self: Vec<T, A>);
        req thread_token(?t) &*& <Vec<T, A>>.own(t, self);
        ens thread_token(t) &*& Vec::<T, A>(self, ?capacity, ?elems) &*& foreach(elems, own::<T>(t));
    
    lem init_ref_Vec<T, A>(p: *Vec<T, A>);
        req ref_init_perm(p, ?x) &*& [?f](*x |-> ?v);
        ens ref_end_token(p, x, f/2) &*& [f/2](*x |-> v) &*& [f/2](*p |-> v) &*& ref_initialized(p);
    
    lem end_ref_Vec<T, A>(p: *Vec<T, A>);
        req ref_end_token(p, ?x, ?f) &*& [f](*p |-> ?v) &*& ref_initialized(p);
        ens [f](*x |-> v);
    
    @*/
    
    impl<T> Vec<T> {
    
        fn new() -> Vec<T, std::alloc::Global>;
        //@ req true;
        //@ ens Vec(result, _, []);
        //@ on_unwind_ens false;
    
    }
    
    impl<T, A> Vec<T, A> {
    
        fn len<'a>(self: &'a Vec<T, A>) -> usize;
        //@ req [?f](*self |-> ?self_) &*& [?fv]Vec::<T, A>(self_, ?capacity, ?elems);
        //@ ens [f](*self |-> self_) &*& [fv]Vec::<T, A>(self_, capacity, elems) &*& result == length(elems);
        //@ on_unwind_ens false;
    
        fn push<'a>(self: &'a Vec<T, A>, elem: T);
        //@ req thread_token(?t) &*& *self |-> ?self0 &*& Vec::<T, A>(self0, _, ?elems0) &*& drop_perm::<T>(?charged, ?R, t, elem);
        //@ ens thread_token(t) &*& *self |-> ?self1 &*& Vec::<T, A>(self1, _, append(elems0, [elem])) &*& drop_perm::<T>(charged, R, t, elem);
        //@ on_unwind_ens thread_token(t) &*& *self |-> ?self1 &*& Vec::<T, A>(self1, _, elems0);
        
        fn reserve<'a>(self: &'a Vec<T, A>, additional: usize);
        //@ req *self |-> ?self0 &*& Vec::<T, A>(self0, _, ?elems);
        //@ ens *self |-> ?self1 &*& Vec::<T, A>(self1, ?capacity, elems) &*& length(elems) + additional <= capacity;
        //@ on_unwind_ens *self |-> ?self1 &*& Vec::<T, A>(self1, _, elems);
        
        fn as_mut_ptr<'a>(self: &'a Vec<T, A>) -> *mut T;
        //@ req [?f](*self |-> ?self_) &*& [f]Vec_minus_buffer::<T, A>(self_, ?capacity, ?len, ?buffer);
        //@ ens [f](*self |-> self_) &*& [f]Vec_minus_buffer::<T, A>(self_, capacity, len, buffer) &*& result == buffer;
        //@ on_unwind_ens false;
        
        fn as_ptr<'a>(self: &'a Vec<T, A>) -> *const T;
        //@ req [?f](*self |-> ?self_) &*& [f]Vec_minus_buffer::<T, A>(self_, ?capacity, ?len, ?buffer);
        //@ ens [f](*self |-> self_) &*& [f]Vec_minus_buffer::<T, A>(self_, capacity, len, buffer) &*& result == buffer;
        //@ on_unwind_ens false;

        fn spare_capacity_mut<'a>(self: &'a Vec<T, A>) -> &'a [T];
        //@ req [?f](*self |-> ?self_) &*& [f]Vec_minus_buffer::<T, A>(self_, ?capacity, ?len, ?buffer);
        //@ ens [f](*self |-> self_) &*& [f]Vec_minus_buffer::<T, A>(self_, capacity, len, buffer) &*& result.ptr == buffer + len &*& result.len == capacity - len;
        //@ on_unwind_ens false;

        fn set_len<'a>(self: &'a Vec<T, A>, new_len: usize);
        //@ req *self |-> ?self0 &*& Vec_minus_buffer::<T, A>(self0, ?capacity, ?len, ?buffer) &*& new_len <= capacity;
        //@ ens *self |-> ?self1 &*& Vec_minus_buffer::<T, A>(self1, capacity, new_len, buffer);
        //@ on_unwind_ens false;
        
    }
    
}

mod io {

    struct Error;
    
    type Result<T> = std::result::Result<T, Error>;
    
    trait Write {
    
        fn write<'a, 'b>(self: &'a Self, buf: &'b [u8]) -> Result<usize>;
        //@ req thread_token(?t) &*& *self |-> ?self0 &*& <Self>.own(t, self0) &*& [?f]buf.ptr[..buf.len] |-> ?bs;
        //@ ens thread_token(t) &*& *self |-> ?self1 &*& <Self>.own(t, self1) &*& [f]buf.ptr[..buf.len] |-> bs &*& std::result::Result_own::<usize, Error>(t, result);
        //@ on_unwind_ens thread_token(t) &*& *self |-> ?self1 &*& <Self>.own(t, self1) &*& [f]buf.ptr[..buf.len] |-> _;
        
        fn flush<'a>(self: &'a Self) -> Result<()>;
        //@ req thread_token(?t) &*& *self |-> ?self0 &*& <Self>.own(t, self0);
        //@ ens thread_token(t) &*& *self |-> ?self1 &*& <Self>.own(t, self1);
        //@ on_unwind_ens thread_token(t) &*& *self |-> ?self1 &*& <Self>.own(t, self1);
        
    }

    struct Stdout;
    
    fn stdout() -> Stdout;
    //@ req thread_token(?t);
    //@ ens thread_token(t) &*& <Stdout>.own(t, result);
    //@ on_unwind_ens thread_token(t);

}

mod sync {
    mod atomic {

        enum Ordering {
            Relaxed,
            SeqCst
        }

        struct AtomicUsize;

        /*@
        
        lem_auto size_of_AtomicUsize();
            req true;
            ens std::mem::size_of::<AtomicUsize>() == std::mem::size_of::<usize>();
        
        lem_auto align_of_AtomicUsize();
            req true;
            ens std::mem::align_of::<AtomicUsize>() == std::mem::size_of::<usize>();
        
        fix AtomicUsize::inner(v: AtomicUsize) -> usize;
        pred AtomicUsize(p: *AtomicUsize; v: usize) = *p |-> ?v_ &*& v == v_.inner();
        
        lem AtomicUsize_to_usize(p: *AtomicUsize);
            req *p |-> ?v;
            ens *(p as *usize) |-> v.inner() &*& (p as usize) % std::mem::size_of::<usize>() == 0;

        lem usize_to_AtomicUsize(p: *usize);
            nonghost_callers_only
            req *p |-> ?v0 &*& (p as usize) % std::mem::size_of::<usize>() == 0;
            ens AtomicUsize(p as *AtomicUsize, v0);

        lem_type AtomicUsize_fetch_add_op(self: *AtomicUsize, val: usize, P: pred(), Q: pred(usize)) = lem();
            req AtomicUsize(self, ?v0) &*& P();
            ens AtomicUsize(self, (v0 + val) % (usize::MAX + 1)) &*& Q(v0);

        lem_type AtomicUsize_fetch_add_ghop(self: *AtomicUsize, val: usize, pre: pred(), post: pred(usize)) = lem();
            req atomic_mask(MaskTop) &*& is_AtomicUsize_fetch_add_op(?op, self, val, ?P, ?Q) &*& P() &*& pre();
            ens atomic_mask(MaskTop) &*& is_AtomicUsize_fetch_add_op(op, self, val, P, Q) &*& Q(?result) &*& post(result);

        lem_type AtomicUsize_fetch_sub_op(self: *AtomicUsize, val: usize, P: pred(), Q: pred(usize)) = lem();
            req AtomicUsize(self, ?v0) &*& P();
            ens AtomicUsize(self, (v0 - val + usize::MAX + 1) % (usize::MAX + 1)) &*& Q(v0);

        lem_type AtomicUsize_fetch_sub_ghop(self: *AtomicUsize, val: usize, pre: pred(), post: pred(usize)) = lem();
            req atomic_mask(MaskTop) &*& is_AtomicUsize_fetch_sub_op(?op, self, val, ?P, ?Q) &*& P() &*& pre();
            ens atomic_mask(MaskTop) &*& is_AtomicUsize_fetch_sub_op(op, self, val, P, Q) &*& Q(?result) &*& post(result);

        lem_type AtomicUsize_load_op(self: *AtomicUsize, P: pred(), Q: pred(usize)) = lem();
            req [?f]AtomicUsize(self, ?v) &*& P();
            ens [f]AtomicUsize(self, v) &*& Q(v);

        lem_type AtomicUsize_load_ghop(self: *AtomicUsize, pre: pred(), post: pred(usize)) = lem();
            req atomic_mask(MaskTop) &*& is_AtomicUsize_load_op(?op, self, ?P, ?Q) &*& P() &*& pre();
            ens atomic_mask(MaskTop) &*& is_AtomicUsize_load_op(op, self, P, Q) &*& Q(?result) &*& post(result);

        lem_type AtomicUsize_compare_exchange_op(self: *AtomicUsize, current: usize, new: usize, P: pred(), Q: pred(std::result::Result<usize, usize>)) = lem();
            req AtomicUsize(self, ?v0) &*& P();
            ens if v0 == current { AtomicUsize(self, new) &*& Q(std::result::Result::Ok(v0)) } else
                { AtomicUsize(self, v0) &*& Q(std::result::Result::Err(v0)) };

        lem_type AtomicUsize_compare_exchange_ghop(self: *AtomicUsize, current: usize, new: usize, pre: pred(), post: pred(std::result::Result<usize, usize>)) = lem();
            req atomic_mask(MaskTop) &*& is_AtomicUsize_compare_exchange_op(?op, self, current, new, ?P, ?Q) &*& P() &*& pre();
            ens atomic_mask(MaskTop) &*& is_AtomicUsize_compare_exchange_op(op, self, current, new, P, Q) &*& Q(?result) &*& post(result);
        
        @*/

        impl AtomicUsize {
            fn new(v: usize) -> AtomicUsize;
            //@ req true;
            //@ ens result.inner() == v;
            //@ on_unwind_ens false;

            fn from_ptr<'a>(ptr: *mut usize) -> &'a AtomicUsize;
            //@ req ptr as usize % std::mem::align_of::<AtomicUsize>() == 0;
            //@ ens result as *mut usize == ptr;
            //@ on_unwind_ens false;

            fn fetch_add<'a>(self: &'a AtomicUsize, val: usize, order: Ordering) -> usize;
            /*@
            req match order {
                    Ordering::Relaxed => false,
                    Ordering::SeqCst => is_AtomicUsize_fetch_add_ghop(?ghop, self, val, ?pre, ?post) &*& pre() &*& ens post(result) on_unwind_ens false,
                };
            @*/
            //@ ens true;
            //@ on_unwind_ens false;

            fn fetch_sub<'a>(self: &'a AtomicUsize, val: usize, order: Ordering) -> usize;
            //@ req order == std::sync::atomic::Ordering::SeqCst &*& is_AtomicUsize_fetch_sub_ghop(?ghop, self, val, ?pre, ?post) &*& pre();
            //@ ens post(result);
            //@ on_unwind_ens false;

            fn load<'a>(self: &'a AtomicUsize, order: Ordering) -> usize;
            //@ req order == std::sync::atomic::Ordering::SeqCst &*& is_AtomicUsize_load_ghop(?ghop, self, ?pre, ?post) &*& pre();
            //@ ens post(result);
            //@ on_unwind_ens false;

            fn compare_exchange<'a>(self: &'a AtomicUsize, current: usize, new: usize, success: Ordering, failure: Ordering) -> std::result::Result<usize, usize>;
            /*@ req success == std::sync::atomic::Ordering::SeqCst &*& failure == std::sync::atomic::Ordering::SeqCst &*&
                is_AtomicUsize_compare_exchange_ghop(?ghop, self, current, new, ?pre, ?post) &*& pre(); @*/
            //@ ens post(result);
            //@ on_unwind_ens false;
        }

        trait AtomicPrimitive {

            type AtomicInner;

        }

    }
    
    struct Mutex<T>;
    struct MutexGuard<'a, T>;
    
    //@ fix Mutex::data_ptr<T>(self: *mut Mutex<T>) -> *mut T;
    
    //@ pred Mutex<T>(mutex: Mutex<T>, value: T);
    //@ pred Mutex_minus_data<T>(mutex: *mut Mutex<T>);
    //@ pred Mutex_shared<T>(mutex: *Mutex<T>; inv_: pred());
    //@ pred MutexGuard<'a, T>(t: thread_id_t, guard: MutexGuard<'a, T>, inv_: pred());
    //@ pred Mutex_lock_end_token<T>(mutex: *Mutex<T>, inv_: pred(), k: lifetime_t, frac: real);
    
    /*@
    
    lem Mutex_separate_data<T>(mutex_ptr: *mut Mutex<T>);
        req *mutex_ptr |-> ?mutex &*& Mutex(mutex, ?value);
        ens Mutex_minus_data(mutex_ptr) &*& *Mutex::data_ptr(mutex_ptr) |-> value;

    lem share_Mutex<T>(mutex: *mut Mutex<T>);
        req Mutex_minus_data(mutex) &*& exists::<pred()>(?inv_) &*& inv_();
        ens Mutex_shared(mutex, inv_);
        
    lem MutexGuard_to_own<'a, T>(guard: MutexGuard<'a, T>);
        req MutexGuard::<'a, T>(?t, guard, ?inv_) &*& inv_();
        ens <MutexGuard<'a, T>>.own(t, guard);
    
    lem end_Mutex_lock<T>(mutex: *mut Mutex<T>);
        req Mutex_lock_end_token(mutex, ?inv_, ?k, ?frac) &*& [_]lifetime_dead_token(k);
        ens [frac]Mutex_shared(mutex, inv_);
    
    @*/
    
    struct PoisonError<T>;
        
    impl<T> Mutex<T> {
    
        fn new(init: T) -> Mutex<T>;
        //@ req true;
        //@ ens Mutex(result, init);
    
        fn data_ptr<'a>(self: &'a Mutex<T>) -> *mut T;
        //@ req true;
        //@ ens result == Mutex::data_ptr(self);
        
        fn lock<'a>(self: &'a Mutex<T>) -> std::result::Result<MutexGuard<'a, T>, PoisonError<MutexGuard<'a, T>>>;
        //@ req thread_token(currentThread) &*& [?frac]Mutex_shared(self, ?inv_);
        /*@
        ens thread_token(currentThread) &*&
            match result {
                Result::Ok(guard) => MutexGuard(currentThread, guard, inv_) &*& inv_() &*& Mutex_lock_end_token(self, inv_, 'a, frac),
                Result::Err(err) => <PoisonError<MutexGuard<'a, T>>>.own(currentThread, err)
            };
        @*/
    
    }
    
}

mod thread {

    struct JoinHandle<T>;
    
    fn sleep(duration: std::time::Duration);
    //@ req true;
    //@ ens true;
    //@ on_unwind_ens true;
    
}

mod time {

    struct Duration;
    
    impl Duration {
    
        fn from_millis(millis: u64) -> Duration;
        //@ req true;
        //@ ens true;
        //@ on_unwind_ens true;

    }
    
}

mod iter {

    trait Iterator {
        
        type Item;
        
        fn next<'a>(self: &'a mut Self) -> std::option::Option< <Self as std::iter::Iterator>::Item>;
        //@ req thread_token(?t) &*& *self |-> ?self0 &*& <Self>.own(t, self0);
        //@ ens thread_token(t) &*& *self |-> ?self1 &*& <Self>.own(t, self1) &*& <std::option::Option< <Self as std::iter::Iterator>::Item>>.own(t, result);
        //@ on_unwind_ens thread_token(t) &*& *self |-> ?self1 &*& <Self>.own(t, self1);
        
    }
    
}

mod fmt {

    struct Arguments<'a>;
    
    mod rt {
    
        impl<'a> std::fmt::Arguments<'a> {
        
            fn new_const<N>(pieces: &'a [&'a str; N]) -> std::fmt::Arguments<'a>;
            //@ req thread_token(?t) &*& <&'a [&'a str; N]>.own(t, pieces);
            //@ ens thread_token(t) &*& <std::fmt::Arguments<'a>>.own(t, result);
            //@ on_unwind_ens thread_token(t);
        
        }
    
    }

}

mod panicking {

    enum AssertKind {
        Eq,
        Ne,
        Match
    }
    
    fn panic<'a>(msg: &'a str);
    //@ req [?f]msg.ptr[..msg.len] |-> ?cs;
    //@ ens false;
    //@ on_unwind_ens [f]msg.ptr[..msg.len] |-> cs;

    fn panic_fmt<'a>(args: std::fmt::Arguments<'a>);
    //@ req thread_token(?t) &*& <std::fmt::Arguments<'a>>.own(t, args);
    //@ ens false;
    //@ on_unwind_ens thread_token(t);

}

mod rt {

    fn panic_fmt<'a>(args: std::fmt::Arguments<'a>);
    //@ req thread_token(?t) &*& <std::fmt::Arguments<'a>>.own(t, args);
    //@ ens false;
    //@ on_unwind_ens thread_token(t);

}

mod convert {

    struct Infallible {}
    
    trait Into<T> {
    
        fn into(self: Self) -> T;
        //@ req thread_token(currentThread) &*& <Self>.own(currentThread, self);
        //@ ens thread_token(currentThread) &*& <T>.own(currentThread, result);
    
    }
    
}
