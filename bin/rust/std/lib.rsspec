/*@

abstract_type type_info;

@*/

mod verifast {

    // Used to translate Rust array literals of the form &[V1, V2, V3]
    fn produce_const_ref<T>() -> &'static T;
    //@ req thread_token(?t);
    //@ ens thread_token(t) &*& <&'static T>.own(t, result) &*& [_]ref_initialized(result);
    //@ on_unwind_ens false;

}

mod hint {

    fn assert_unchecked(b: bool);
    //@ req b;
    //@ ens true;
    //@ on_unwind_ens false;

}

mod ops {

    trait FnOnce<Args> {

        type Output;
    
        fn call_once(self: Self, args: Args) -> <Self as std::ops::FnOnce<Args>>::Output;
        //@ req thread_token(?t) &*& <Self>.own(t, self) &*& <Args>.own(t, args);
        //@ ens thread_token(t) &*& < <Self as std::ops::FnOnce<Args>>::Output>.own(t, result);
        //@ on_unwind_ens thread_token(t);
        
    }

    trait FnMut<Args> {
    
        fn call_mut<'a>(self: &'a mut Self, args: Args) -> <Self as std::ops::FnOnce<Args>>::Output;
        //@ req thread_token(?t) &*& *self |-> ?self0 &*& <Self>.own(t, self0) &*& <Args>.own(t, args);
        //@ ens thread_token(t) &*& *self |-> ?self1 &*& <Self>.own(t, self1) &*& < <Self as std::ops::FnOnce<Args>>::Output>.own(t, result);
        //@ on_unwind_ens thread_token(t) &*& *self |-> ?self1 &*& <Self>.own(t, self1);
        
    }
    
    trait Fn<Args> {
    
        fn call<'a>(self: &'a Self, args: Args) -> <Self as std::ops::FnOnce<Args>>::Output;
        //@ req thread_token(?t) &*& [?q]lifetime_token('a) &*& [_](<Self>.share('a, t, self)) &*& <Args>.own(t, args);
        //@ ens thread_token(t) &*& [q]lifetime_token('a) &*& < <Self as std::ops::FnOnce<Args>>::Output>.own(t, result);
        //@ on_unwind_ens thread_token(t) &*& [q]lifetime_token('a);
        
    }
    
    struct Range<Idx> {
        start: Idx,
        end: Idx,
    }
    
    impl std::iter::IntoIterator for std::ops::Range<usize> {
    
        fn into_iter(self: Range<usize>) -> Range<usize>;
        //@ req true;
        //@ ens result == self;
        //@ on_unwind_ens false;
    
    }
    
    impl std::iter::Iterator for std::ops::Range<usize> {
    
        fn next<'a>(self: &'a mut Range<usize>) -> std::option::Option<usize>;
        //@ req *self |-> ?self0;
        /*@
        ens if self0.start < self0.end {
                *self |-> Range::<usize> { start: self0.start + 1, end: self0.end } &*& result == std::option::Option::Some(self0.start)
            } else {
                *self |-> self0 &*& result == std::option::Option::None
            };
        @*/
        //@ on_unwind_ens false;
        
    }
    
    enum ControlFlow<B, C> {
        Continue(C),
        Break(B)
    }
    
}

mod rt {

    fn begin_panic<M>(msg: M); // Generated by the assert! macro
    //@ req true; // TODO: Express that the message is valid.
    //@ ens false;
    //@ on_unwind_ens true;

}

mod num {

    /*@
    
    lem init_ref_usize(p: *usize, coef: real);
        req ref_init_perm::<usize>(p, ?x) &*& [?f](*x |-> ?v) &*& 0 < coef &*& coef < 1;
        ens ref_initialized(p) &*& [coef*f](*p |-> v) &*& [(1 - coef)*f](*x |-> v) &*& ref_end_token(p, x, coef*f);
    
    lem end_ref_usize(p: *usize);
        req ref_initialized(p) &*& ref_end_token(p, ?x, ?f) &*& [f](*p |-> ?v);
        ens [f](*x |-> v);
    
    @*/

    impl usize {
    
        fn checked_sub(self: usize, other: usize) -> std::option::Option<usize>;
        //@ req true;
        //@ ens if self < other { result == std::option::Option::None } else { result == std::option::Option::Some(self - other) };
        //@ on_unwind_ens false;

        fn checked_add(self: usize, other: usize) -> std::option::Option<usize>;
        //@ req true;
        //@ ens if self + other > usize::MAX { result == std::option::Option::None } else { result == std::option::Option::Some(self + other) };
        //@ on_unwind_ens false;
        
    }
    
    mod niche_types {
    
        struct UsizeNoHighBit;
    
    }

}

mod marker {

    struct PhantomData<T> {}
    
    /*@
    
    lem close_PhantomData_own<T>(t: thread_id_t, marker: PhantomData<T>);
        req true;
        ens <PhantomData<T>>.own(t, marker);
    
    lem close_ref_initialized_PhantomData<T>(marker: *PhantomData<T>, f: real);
        req true;
        ens [f]ref_initialized::<PhantomData<T>>(marker);
    
    @*/
    
}

mod intrinsics {

    unsafe fn copy<T>(src: *mut T, dst: *mut T, count: usize);
    /*@
    req src[..count] |-> ?vs &*&
        if src <= dst {
            ((src + count) as *u8)[..dst as *u8 - src as *u8] |-> _
        } else {
            (dst as *u8)[..src as *u8 - dst as *u8] |-> _
        };
    @*/
    /*@
    ens dst[..count] |-> vs &*&
        if src <= dst {
            (src as *u8)[..dst as *u8 - src as *u8] |-> _
        } else {
            ((dst + count) as *u8)[..src as *u8 - dst as *u8] |-> _
        };
    @*/
    //@ on_unwind_ens false;
    //@ terminates;

    unsafe fn copy_nonoverlapping<T>(src: *mut T, dst: *mut T, count: usize);
    //@ req [?f]src[..count] |-> ?vs &*& dst[..count] |-> _;
    //@ ens [f]src[..count] |-> vs &*& dst[..count] |-> vs;
    //@ on_unwind_ens false;
    //@ terminates;
    
    unsafe fn write_bytes<T>(dst: *mut T, val: u8, count: usize);
    //@ req dst[..count] |-> _ &*& (dst as usize % std::mem::align_of::<T>()) == 0;
    //@ ens (dst as *u8)[..count * std::mem::size_of::<T>()] |-> repeat(nat_of_int(count * std::mem::size_of::<T>()), val);
    //@ on_unwind_ens false;
    //@ terminates;

    unsafe fn ptr_offset_from<T>(ptr: *const T, base: *const T) -> isize;
    /*@
    req
        (ptr as pointer).provenance == (base as pointer).provenance &*&
        (ptr as usize - base as usize) % std::mem::size_of::<T>() == 0 &*&
        isize::MIN <= ptr as usize - base as usize &*& ptr as usize - base as usize <= isize::MAX;
    @*/
    //@ ens result == ptr as usize - base as usize;
    //@ on_unwind_ens false;
    
    // atomic_points_to(p, v) is like points_to(p, v) but additionally, it guarantees that place *p is not accessed
    // with non-read-only mixed-size accesses since converting from points_to to atomic_points_to is possible only
    // at top mask, which means the conversion can be thought of as happening in a separate machine step.
    // Furthermore, it guarantees that p is properly aligned for atomic accesses at type T.
    
    // Note: these specs are sufficient to prove semantic well-typedness of the sync::atomic API, but are not
    // sufficient to prove arbitrary functional correctness properties. TODO: Extend these specs to also support the latter.
    
    /*@
    
    fix atomic_align_of<T>() -> usize;
    
    lem_auto atomic_align_of_u8();
        req true;
        ens atomic_align_of::<u8>() == 1;
    
    lem_auto atomic_align_of_usize();
        req true;
        ens atomic_align_of::<usize>() == std::mem::size_of::<usize>();
    
    pred atomic_points_to<T>(p: *T, frac: real, inv_: fix(T, bool););
    
    lem close_atomic_points_to_m<T>(p: *T, inv_: fix(T, bool));
        req atomic_mask(MaskTop) &*& [?f](*p |-> ?v) &*& p as usize % atomic_align_of::<T>() == 0 &*& inv_(v) == true;
        ens atomic_mask(MaskTop) &*& atomic_points_to(p, f, inv_);
    
    lem open_atomic_points_to<T>(p: *T);
        req atomic_points_to(p, ?f, ?inv_);
        ens [f](*p |-> ?v) &*& inv_(v) == true;
    
    @*/
    
    unsafe fn atomic_store_relaxed<T>(dst: *mut T, val: T);
    //@ req [?f]atomic_points_to(dst, 1, ?inv_) &*& inv_(val) == true;
    //@ ens [f]atomic_points_to(dst, 1, inv_);
    //@ on_unwind_ens false;
    
    unsafe fn atomic_store_release<T>(dst: *mut T, val: T);
    //@ req [?f]atomic_points_to(dst, 1, ?inv_) &*& inv_(val) == true;
    //@ ens [f]atomic_points_to(dst, 1, inv_);
    //@ on_unwind_ens false;
    
    unsafe fn atomic_store_seqcst<T>(dst: *mut T, val: T);
    //@ req [?f]atomic_points_to(dst, 1, ?inv_) &*& inv_(val) == true;
    //@ ens [f]atomic_points_to(dst, 1, inv_);
    //@ on_unwind_ens false;
    
}

mod mem {

    //@ fix size_of_<T>() -> usize { std::mem::size_of::<T>() }
    //@ fix align_of_<T>() -> usize { std::mem::align_of::<T>() }

    fn size_of<T>() -> usize;
    //@ req true;
    //@ ens result == std::mem::size_of_::<T>();
    //@ on_unwind_ens false;
    
    fn align_of<T>() -> usize;
    //@ req true;
    //@ ens result == std::mem::align_of_::<T>();
    //@ on_unwind_ens false;

    fn drop<T>(value: T);
    //@ req thread_token(?t) &*& <T>.own(t, value);
    //@ ens thread_token(t);
    //@ on_unwind_ens thread_token(t);
    
    fn forget<T>(value: T);
    //@ req thread_token(?t) &*& <T>.own(t, value);
    //@ ens thread_token(t);
    //@ on_unwind_ens false;
    
    fn replace<T, 'a>(dest: &'a mut T, src: T) -> T;
    //@ req *dest |-> ?v;
    //@ ens *dest |-> src &*& result == v;
    //@ on_unwind_ens false;
    
    struct MaybeUninit<T>;
    
    /*@
    
    fix MaybeUninit::inner<T>(v: MaybeUninit<T>) -> option<T>;
    fix MaybeUninit::new_<T>(v: T) -> MaybeUninit<T>;
    fix MaybeUninit::uninit_<T>() -> MaybeUninit<T>;
    fix MaybeUninit::new_maybe_uninit<T>(v: option<T>) -> MaybeUninit<T>;
    
    lem_auto MaybeUninit_inner_new_<T>(v: T);
        req true;
        ens MaybeUninit::inner(MaybeUninit::new_(v)) == some(v);
    
    lem_auto MaybeUninit_inner_new_maybe_uninit<T>(v: option<T>);
        req true;
        ens MaybeUninit::inner(MaybeUninit::new_maybe_uninit(v)) == v;
    
    lem open_MaybeUninit<T>(self: *MaybeUninit<T>);
        req *self |-> ?value;
        ens *(self as *T) |-?-> MaybeUninit::inner(value);
    
    lem close_MaybeUninit_<T>(self: *MaybeUninit<T>);
        req *(self as *T) |-?-> ?value;
        ens *self |-> MaybeUninit::new_maybe_uninit(value);
        
    lem close_MaybeUninit<T>(self: *MaybeUninit<T>);
        req *(self as *T) |-> ?value;
        ens *self |-> MaybeUninit::new_(value);
    
    lem open_MaybeUninit_<T>(self: *MaybeUninit<T>);
        req *self |-?-> ?value;
        ens *(self as *T) |-?-> match value { none => none, some(value_) => MaybeUninit::inner(value_) };
    
    lem MaybeUninit__to_MaybeUninit<T>(self: *MaybeUninit<T>);
        req *self |-?-> ?value;
        ens *self |-> match value { none => MaybeUninit::uninit_(), some(value_) => value_ };
    
    lem Array__MaybeUninit_to_Array_MaybeUninit<T, N>(self: *[MaybeUninit<T>; N]);
        req *self |-?-> ?value_;
        ens *self |-> match value_ { none => Array_of_elems(repeat(nat_of_int(usize_of_const(typeid(N))), MaybeUninit::uninit_())), some(value) => value };
    
    lem array__MaybeUninit_to_array_MaybeUninit<T>(self: *MaybeUninit<T>);
        req self[..?n] |-?-> ?elems_;
        ens self[..n] |-> map((unwrap_or_else)(MaybeUninit::uninit_), elems_);
    
    @*/
    
    impl<T> MaybeUninit<T> {
    
        fn write<'a>(self: &'a mut MaybeUninit<T>, value: T) -> &'a mut T;
        //@ req *self |-> _;
        //@ ens *self |-> MaybeUninit::new_(value);
        //@ on_unwind_ens false;
        
    }
    
    mod verifast {
    
        fn unfreeze<T>(ptr: *T);
        //@ req [1/2](*ptr |-> ?v);
        //@ ens *ptr |-> v;
        //@ on_unwind_ens false;
        
        fn freeze<T>(ptr: *T);
        //@ req *ptr |-> _;
        //@ ens [1/2](*ptr |-> _);
        //@ on_unwind_ens false;
    
    }
    
}

mod ptr {

    unsafe fn drop_in_place<T>(to_drop: *mut T);
    //@ req thread_token(?t) &*& *to_drop |-> ?v &*& <T>.own(t, v);
    //@ ens thread_token(t) &*& *to_drop |-> _;
    //@ on_unwind_ens thread_token(t) &*& *to_drop |-> _;

    struct NonNull<T>;
    
    /*@
    
    lem close_NonNull_own<T>(t: thread_id_t, v: NonNull<T>);
        req true;
        ens (NonNull_own::<T>())(t, v);
        
    lem open_NonNull_own<T>(t: thread_id_t, v: NonNull<T>);
        req [_](NonNull_own::<T>())(t, v);
        ens NonNull_ptr(v) as usize != 0;
        
    fix NonNull_ptr<_T>(v: NonNull<_T>) -> *_T;
    
    // If ptr is 0, the result of NonNull::new_ is unspecified. (It is never the case that NonNull_ptr(nnp) == 0.)
    fix NonNull::new_<T>(ptr: *T) -> NonNull<T>;
    
    lem NonNull_ptr_new<T>(ptr: *T);
        req ptr != 0;
        ens NonNull_ptr(NonNull::new_(ptr)) == ptr;
    
    lem NonNull_upcast<T0, T1>(v: NonNull<T0>);
        req true;
        ens NonNull_ptr::<T1>(upcast(v)) == NonNull_ptr::<T0>(v) as *_;
    
    lem init_ref_NonNull<T>(p: *NonNull<T>, coef: real);
        req ref_init_perm(p, ?x) &*& [?f](*x |-> ?v) &*& 0 < coef &*& coef < 1;
        ens ref_initialized(p) &*& [(1 - coef)*f](*x |-> v) &*& [coef*f](*p |-> v) &*& ref_end_token(p, x, coef*f);
    
    lem end_ref_NonNull<T>(p: *NonNull<T>);
        req ref_initialized(p) &*& ref_end_token(p, ?x, ?f) &*& [f](*p |-> ?v);
        ens [f](*x |-> v);
    
    @*/

    impl<T> NonNull<T> {
        unsafe fn new_unchecked(ptr: *mut T) -> NonNull<T>;
        //@ req ptr as usize != 0;
        //@ ens NonNull_ptr(result) == ptr;
        //@ on_unwind_ens false;
        
        unsafe fn as_mut<'a, 'b>(self: &'b mut NonNull<T>) -> &'a mut T;
        //@ req *self |-> ?v;
        //@ ens *self |-> v &*& result == NonNull_ptr(v);
        //@ on_unwind_ens false;

        unsafe fn as_ref<'a, 'b>(self: &'b NonNull<T>) -> &'a T;
        //@ req [?q](*self) |-> ?v;
        //@ ens [q](*self) |-> v &*& result == NonNull_ptr(v);
        //@ on_unwind_ens false;

        fn as_ptr(self: NonNull<T>) -> *mut T;
        //@ req true;
        //@ ens result == NonNull_ptr(self);
        //@ on_unwind_ens false;
        
        fn cast<U>(self:  NonNull<T>) -> NonNull<U>;
        //@ req true;
        //@ ens result == NonNull::new_(NonNull_ptr(self) as *U);
    }
    
    struct Unique<T>;
    
}

mod alloc {

    struct Layout;
    //@ fix Layout::size_(layout: Layout) -> usize;
    //@ fix Layout::align_(layout: Layout) -> usize;
    //@ fix Layout::from_size_align_(size: usize, align: usize) -> Layout;
    //@ fix Layout::new_<T>() -> Layout { Layout::from_size_align_(std::mem::size_of_::<T>(), std::mem::align_of_::<T>()) }
    
    /*@
    
    lem_auto Layout_size__Layout_from_size_align_(size: usize, align: usize);
        req true;
        ens Layout::size_(Layout::from_size_align_(size, align)) == size;
    
    lem_auto Layout_align__Layout_from_size_align_(size: usize, align: usize);
        req true;
        ens Layout::align_(Layout::from_size_align_(size, align)) == align;
    
    @*/
    
    impl Layout {
    
        fn new<T>() -> Layout;
        //@ req true;
        //@ ens result == Layout::new_::<T>();
        //@ on_unwind_ens false;

        fn from_size_align_unchecked(size: usize, align: usize) -> Layout;
        //@ req is_power_of_2(align) == true && size <= isize::MAX - isize::MAX % align;
        //@ ens result == Layout::from_size_align_(size, align);
        //@ on_unwind_ens false;

    }
    
    //@ pred alloc_block(ptr: *u8; layout: Layout);
    //@ pred alloc_block_in(alloc_id: any, ptr: *u8, layout: Layout;);
    
    /*@
    
    lem alloc_aligned(ptr: *mut u8);
        req [?f]alloc_block(ptr, ?layout);
        ens [f]alloc_block(ptr, layout) &*& (ptr as usize) % Layout::align_(layout) == 0 &*& ref_origin(ptr) == ptr;
    
    @*/
    
    /*@
    
    pred Allocator<A>(t: thread_id_t, alloc: A, alloc_id: any);
    pred Allocator_share<A>(k: lifetime_t, t: thread_id_t, l: *A, alloc_id: any);
    
    lem Allocator_upcast<A0, A1>(alloc: A0);
        req Allocator::<A0>(?t, alloc, ?alloc_id) &*& is_subtype_of::<A0, A1>() == true;
        ens Allocator::<A1>(t, upcast(alloc), alloc_id);
    
    lem Allocator_send<A>(t1: thread_id_t, alloc: A);
        req Allocator::<A>(?t0, alloc, ?alloc_id) &*& is_Send(typeid(A)) == true;
        ens Allocator::<A>(t1, alloc, alloc_id);
    
    lem Allocator_to_own<A>(alloc: A);
        req Allocator::<A>(?t, alloc, _);
        ens <A>.own(t, alloc);
    
    lem open_Allocator_own<A>(alloc: A);
        req <A>.own(?t, alloc);
        ens Allocator::<A>(t, alloc, _);
    
    fix Allocator_full_borrow_content_<A>(t: thread_id_t, l: *A, alloc_id: any) -> pred();
    
    lem close_Allocator_full_borrow_content_<A>(t: thread_id_t, l: *A);
        req *l |-> ?alloc &*& Allocator::<A>(t, alloc, ?alloc_id);
        ens (Allocator_full_borrow_content_::<A>(t, l, alloc_id))();
    
    lem open_Allocator_full_borrow_content_<A>(t: thread_id_t, l: *A, alloc_id: any);
        req (Allocator_full_borrow_content_::<A>(t, l, alloc_id))();
        ens *l |-> ?alloc &*& Allocator::<A>(t, alloc, alloc_id);
    
    lem share_Allocator_full_borrow_content_<A>(k: lifetime_t, t: thread_id_t, l: *A, alloc_id: any);
        nonghost_callers_only
        req full_borrow(k, Allocator_full_borrow_content_::<A>(t, l, alloc_id)) &*& [?q]lifetime_token(k);
        ens [_]Allocator_share(k, t, l, alloc_id) &*& [q]lifetime_token(k);
    
    lem share_Allocator_full_borrow_content_m<A>(k: lifetime_t, t: thread_id_t, l: *A, alloc_id: any);
        req type_interp::<A>() &*& atomic_mask(MaskTop) &*& full_borrow(k, Allocator_full_borrow_content_::<A>(t, l, alloc_id)) &*& [?q]lifetime_token(k);
        ens type_interp::<A>() &*& atomic_mask(MaskTop) &*& [_]Allocator_share(k, t, l, alloc_id) &*& [q]lifetime_token(k);
    
    lem close_Allocator_share<A>(k: lifetime_t, t: thread_id_t, l: *A);
        req [_]Allocator_share(k, t, l, _);
        ens [_](<A>.share(k, t, l));
    
    lem init_ref_Allocator_share<A>(k: lifetime_t, t: thread_id_t, p: *A);
        nonghost_callers_only
        req ref_init_perm(p, ?x) &*& [_]Allocator_share(k, t, x, ?allocId) &*& [?q]lifetime_token(k);
        ens [q]lifetime_token(k) &*& [_]Allocator_share(k, t, p, allocId) &*& [_]frac_borrow(k, ref_initialized_(p));
    
    lem close_Allocator_ref<'a, A>(t: thread_id_t, l: *A);
        req [_]Allocator_share('a, t, l, ?alloc_id);
        ens Allocator::<&'a A>(t, l, alloc_id);
    
    pred share_allocator_at_lifetime_end_token<A>(t: thread_id_t, l: *A, alloc_id: any, k: lifetime_t);
    
    lem share_allocator_at_lifetime<'a, A>(l: *A);
        nonghost_callers_only
        req *l |-> ?alloc &*& Allocator(?t, alloc, ?alloc_id);
        ens Allocator::<&'a A>(t, l, alloc_id) &*& share_allocator_at_lifetime_end_token(t, l, alloc_id, 'a);
    
    lem end_share_allocator_at_lifetime<A>();
        nonghost_callers_only
        req share_allocator_at_lifetime_end_token::<A>(?t, ?l, ?alloc_id, ?k) &*& [_]lifetime_dead_token(k);
        ens *l |-> ?alloc &*& Allocator::<A>(t, alloc, alloc_id);
    
    pred ref_Allocator_end_token_at_lifetime<A>(t: thread_id_t, p: *A, x: *A, alloc_id: any, k: lifetime_t);
    
    lem init_ref_Allocator_at_lifetime<'a, A>(p: *A);
        nonghost_callers_only
        req ref_init_perm(p, ?x) &*& *x |-> ?alloc &*& Allocator(?t, alloc, ?alloc_id);
        ens ref_initialized(p) &*& Allocator::<&'a A>(t, p, alloc_id) &*& ref_Allocator_end_token_at_lifetime(t, p, x, alloc_id, 'a);
    
    lem end_ref_Allocator_at_lifetime<A>();
        nonghost_callers_only
        req ref_Allocator_end_token_at_lifetime::<A>(?t, ?p, ?x, ?alloc_id, ?k) &*& [_]lifetime_dead_token(k) &*& ref_initialized(p);
        ens *x |-> ?alloc &*& Allocator::<A>(t, alloc, alloc_id);
    
    @*/

    fn alloc(layout: Layout) -> *u8;
    //@ req 1 <= Layout::size_(layout);
    /*@
    ens
        if result == 0 {
            true
        } else {
            ref_origin(result) == result &*&
            result[..Layout::size_(layout)] |-> _ &*& alloc_block(result, layout) &*&
            result as usize % Layout::align_(layout) == 0 &*&
            object_pointer_within_limits(result, Layout::size_(layout)) == true
        };
    @*/
    //@ on_unwind_ens true;
    //@ terminates;
    
    fn realloc(buffer: *u8, layout: Layout, new_size: usize) -> *u8;
    //@ req buffer[..?len] |-> ?vs1 &*& buffer[len..Layout::size_(layout)] |-?-> ?vs2 &*& alloc_block(buffer, layout) &*& Layout::size_(layout) <= new_size;
    /*@
    ens
        if result == 0 {
            buffer[..len] |-> vs1 &*& buffer[len..Layout::size_(layout)] |-?-> vs2 &*& alloc_block(buffer, layout)
        } else {
            result[..len] |-> vs1 &*& result[len..Layout::size_(layout)] |-?-> vs2 &*&
            result[Layout::size_(layout)..new_size] |-> _ &*& alloc_block(result, Layout::from_size_align_(new_size, Layout::align_(layout)))
        };
    @*/
    //@ on_unwind_ens true;
    
    fn dealloc(p: *u8, layout: Layout);
    //@ req alloc_block(p, layout) &*& p[..Layout::size_(layout)] |-> _;
    //@ ens true;
    //@ on_unwind_ens true;
    //@ terminates;
    
    fn handle_alloc_error(layout: Layout);
    //@ req true;
    //@ ens false;
    //@ on_unwind_ens true;
    //@ terminates;
    
    struct Global {}
    
    /*@
    
    fix Global_alloc_id() -> any;
    
    lem produce_Allocator_Global(t: thread_id_t);
        req true;
        ens Allocator(t, Global {}, Global_alloc_id);
    
    @*/
    
}

mod boxed {

    struct Box<T, A>;
    
    /*@
    
    pred Box<T>(self: Box<T, std::alloc::Global>, value: T);
    
    lem Box_to_own<T>(self: Box<T, std::alloc::Global>);
        req thread_token(?t) &*& Box::<T>(self, ?value) &*& <T>.own(t, value);
        ens thread_token(t) &*& <Box<T, std::alloc::Global>>.own(t, self);
    
    pred Box_in<T, A>(t: thread_id_t, self: Box<T, A>, alloc_id: any, value: T);
    
    lem own_to_Box_in<T, A>(self: Box<T, A>);
        req <Box<T, A>>.own(?t, self);
        ens Box_in::<T, A>(t, self, ?alloc_id, ?value) &*& <T>.own(t, value);
    
    lem Box_in_to_own<T, A>(self: Box<T, A>);
        req Box_in::<T, A>(?t, self, ?alloc_id, ?value) &*& <T>.own(t, value);
        ens <Box<T, A>>.own(t, self);
    
    @*/
    
    /*@
    
    // This takes a pointer to a Box because moving the Box invalidates the pointer to the contents! https://github.com/verifast/verifast/issues/685#issuecomment-2626864223
    pred Box_minus_contents_in<T, A>(boxFrac: real, t: thread_id_t, placeFrac: real, self: *Box<T, A>, alloc_id: any; contents_ptr: *T);
    
    lem Box_separate_contents<T, A>(self: *Box<T, A>) -> *T;
        req [?fs](*self |-> ?self0) &*& [?f]Box_in::<T, A>(?t, self0, ?alloc_id, ?value);
        ens Box_minus_contents_in(f, t, fs, self, alloc_id, result) &*& [f](*result |-> value);
    
    lem Box_unseparate_contents<T, A>(self: *Box<T, A>);
        req Box_minus_contents_in(?f, ?t, ?fs, self, ?alloc_id, ?contents_ptr) &*& [f](*contents_ptr |-> ?value);
        ens [fs](*self |-> ?self1) &*& [f]Box_in(t, self1, alloc_id, value);
    
    @*/
    
    /*@
    
    pred init_ref_Box_in_token<T, A>(t: thread_id_t, p: *Box<T, A>, fs: real, x: *Box<T, A>, alloc_id: any, p_contents_ptr: *T, x_contents_ptr: *T, f: real);
    
    lem open_ref_init_perm_Box_in<T, A>(p: *Box<T, A>) -> *T;
        req ref_init_perm::<Box<T, A>>(p, ?x) &*& Box_minus_contents_in::<T, A>(?f, ?t, ?fs, x, ?alloc_id, ?x_contents_ptr);
        ens init_ref_Box_in_token::<T, A>(t, p, fs, x, alloc_id, result, x_contents_ptr, f) &*& ref_init_perm::<T>(result, x_contents_ptr);
    
    lem init_ref_Box_in<T, A>(p: *Box<T, A>, coef: real);
        req init_ref_Box_in_token::<T, A>(?t, p, ?fs, ?x, ?alloc_id, ?p_contents_ptr, ?x_contents_ptr, ?f) &*& ref_initialized::<T>(p_contents_ptr) &*& 0 < coef &*& coef < 1;
        ens ref_initialized::<Box<T, A>>(p) &*& Box_minus_contents_in::<T, A>((1-coef)*f, t, (1-coef)*fs, x, alloc_id, x_contents_ptr) &*& Box_minus_contents_in::<T, A>(coef*f, t, coef*fs, p, alloc_id, p_contents_ptr) &*& ref_end_token(p, x, coef*f);
    
    lem end_ref_Box_in<T, A>(p: *Box<T, A>);
        req ref_initialized::<Box<T, A>>(p) &*& ref_end_token(p, ?x, ?f) &*& Box_minus_contents_in::<T, A>(f, ?t, ?fs, p, ?alloc_id, ?p_contents_ptr);
        ens Box_minus_contents_in::<T, A>(f, t, fs, x, alloc_id, _) &*& ref_initialized::<T>(p_contents_ptr);
    
    @*/

    impl<T> Box<T> {
    
        fn new(x: T) -> Box<T, std::alloc::Global>;
        //@ req thread_token(?t) &*& drop_perm::<T>(?charged, ?R, t, x);
        //@ ens thread_token(t) &*& Box(result, x) &*& drop_perm::<T>(charged, R, t, x);
        //@ on_unwind_ens thread_token(t);
        
        fn from_raw(x: *T) -> Box<T, std::alloc::Global>;
        //@ req *x |-> ?value &*& std::alloc::alloc_block(x as *u8, std::alloc::Layout::new_::<T>());
        //@ ens Box(result, value);
        //@ on_unwind_ens false;
        
    }
    
    impl<T, A> Box<T, A> {
    
        fn new_in(x: T, alloc: A) -> Box<T, A>;
        //@ req thread_token(?t) &*& std::alloc::Allocator(t, alloc, ?alloc_id) &*& drop_perm::<T>(?charged, ?R, t, x);
        //@ ens thread_token(t) &*& Box_in(t, result, alloc_id, x) &*& drop_perm::<T>(charged, R, t, x);
        //@ on_unwind_ens thread_token(t);
        
        fn from_raw_in(x: *T, alloc: A) -> Box<T, A>;
        //@ req *x |-> ?value &*& std::alloc::Allocator(?t, alloc, ?alloc_id) &*& std::alloc::alloc_block_in(alloc_id, x as *u8, std::alloc::Layout::new_::<T>());
        //@ ens Box_in(t, result, alloc_id, value);
        //@ on_unwind_ens false;
    
        fn into_raw(b: Box<T, std::alloc::Global>) -> *T;
        //@ req Box(b, ?value);
        //@ ens *result |-> value &*& std::alloc::alloc_block(result as *u8, std::alloc::Layout::new_::<T>()) &*& result as usize != 0;
        //@ on_unwind_ens false;
        
        fn into_inner(b: Box<T, A>) -> T;
        //@ req thread_token(?t) &*& Box_in::<T, A>(t, b, ?alloc_id, ?value);
        //@ ens thread_token(t) &*& result == value;
        //@ on_unwind_ens thread_token(t);
    
        fn leak<'a>(b: Box<T, A>) -> &'a mut T;
        //@ req Box_in::<T, A>(?t, b, ?alloc_id, ?value);
        //@ ens *result |-> value &*& std::alloc::alloc_block_in(alloc_id, result as *u8, std::alloc::Layout::new_::<T>()) &*& result as *_ as usize != 0;
        //@ on_unwind_ens false;
    
        fn new_uninit_in(alloc: A) -> Box<std::mem::MaybeUninit<T>, A>;
        //@ req thread_token(?t) &*& std::alloc::Allocator(t, alloc, ?alloc_id);
        //@ ens thread_token(t) &*& Box_in(t, result, alloc_id, _);
        //@ on_unwind_ens thread_token(t);
        
        fn as_mut_ptr<'a>(self: &'a mut Box<T, A>) -> *mut T;
        //@ req Box_minus_contents_in(?f, ?t, ?fs, self, ?alloc_id, ?contents_ptr);
        //@ ens Box_minus_contents_in(f, t, fs, self, alloc_id, contents_ptr) &*& result == contents_ptr;
        
    }
    
    impl<T, A> Box<std::mem::MaybeUninit<T>, A> {

        fn assume_init(b: Box<std::mem::MaybeUninit<T>, A>) -> Box<T, A>;
        //@ req Box_in(?t, b, ?alloc_id, ?value) &*& std::mem::MaybeUninit::inner(value) == some(?value_);
        //@ ens Box_in(t, result, alloc_id, value_);

    }

}

mod process {
    fn abort();
    //@ req true;
    //@ ens false;
    //@ on_unwind_ens false;
    //@ terminates;

    fn exit(code: i32);
    //@ req true;
    //@ ens false;
    //@ on_unwind_ens false;
    //@ terminates;
}
//Todo @Nima: Edit Rust parser so it substitutes `!` type with std_empty_ union

mod option {

    enum Option<T> {
        None,
        Some(T),
    }
    
    /*@
    
    fix Option_Some_0_offset<T>() -> usize;
    fix Option_Some_0_ptr<T>(ptr: *Option<T>) -> *T { field_ptr(ptr as pointer, typeid(T), Option_Some_0_offset::<T>()) as *T }
    
    pred Option_Some<T>(l: *Option<T>;); // Represents ownership of the discriminant
    
    lem open_points_to_Option_Some<T>(l: *Option<T>);
        req [?f](*l |-> Option::Some(?v0));
        ens [f]Option_Some(l) &*& [f](*Option_Some_0_ptr(l) |-> v0);
    
    lem close_points_to_Option_Some<T>(l: *Option<T>);
        req [?f]Option_Some(l) &*& [f](*Option_Some_0_ptr(l) |-> ?v0);
        ens [f](*l |-> Option::Some(v0));
    
    lem init_ref_Option_None<T>(p: *Option<T>, coef: real);
        req ref_init_perm::<Option<T>>(p, ?x) &*& [?f](*x |-> Option::None) &*& 0 < coef &*& coef < 1;
        ens ref_initialized::<Option<T>>(p) &*& ref_end_token(p, x, coef*f) &*& [(1-coef)*f](*x |-> Option::None) &*& [coef*f](*p |-> Option::None);
    
    pred init_ref_Option_Some_token<T>(p: *Option<T>, x: *Option<T>, frac: real);
    
    lem open_ref_init_perm_Option_Some<T>(p: *Option<T>);
        req ref_init_perm::<Option<T>>(p, ?x) &*& [?f]Option_Some::<T>(x);
        ens init_ref_Option_Some_token::<T>(p, x, f) &*& ref_init_perm::<T>(Option_Some_0_ptr(p), Option_Some_0_ptr(x));
    
    lem init_ref_Option_Some<T>(p: *Option<T>, coef: real);
        req init_ref_Option_Some_token::<T>(p, ?x, ?f) &*& ref_initialized::<T>(Option_Some_0_ptr(p)) &*& 0 < coef &*& coef < 1;
        ens ref_initialized::<Option<T>>(p) &*& [(1-coef)*f]Option_Some::<T>(x) &*& [coef*f]Option_Some::<T>(p) &*& ref_end_token(p, x, coef*f);
    
    lem end_ref_Option_None<T>(p: *Option<T>);
        req ref_initialized::<Option<T>>(p) &*& ref_end_token(p, ?x, ?f) &*& [f](*p |-> Option::None);
        ens [f](*x |-> Option::None);
    
    lem end_ref_Option_Some<T>(p: *Option<T>);
        req ref_initialized::<Option<T>>(p) &*& ref_end_token(p, ?x, ?f) &*& [f]Option_Some::<T>(p);
        ens [f]Option_Some::<T>(x) &*& ref_initialized::<T>(Option_Some_0_ptr(p));
    
    @*/
    
    impl<T> Option<T> {
    
        fn is_some<'a>(self: &'a Option<T>) -> bool;
        //@ req [?f](*self |-> ?v);
        //@ ens [f](*self |-> v) &*& result == (v != Option::None);
        //@ on_unwind_ens false;
        
        fn take<'a>(self: &'a mut Option<T>) -> Option<T>;
        //@ req *self |-> ?v;
        //@ ens *self |-> Option::None &*& result == v;
        //@ on_unwind_ens false;
        
        fn unwrap_or(self: Option<T>, default: T) -> T;
        //@ req true;
        //@ ens result == match self { Option::None => default, Option::Some(v) => v };
        //@ on_unwind_ens false;
        
        fn unwrap_unchecked(self: Option<T>) -> T;
        //@ req self == Option::Some(?v);
        //@ ens result == v;
        //@ on_unwind_ens false;
        
    }
    
    impl<T> std::ops::Try for std::option::Option<T> {
    
        fn branch(self: Option<T>) -> std::ops::ControlFlow<Option<std::convert::Infallible>, T>;
        //@ req true;
        /*@
        ens match self {
                Option::None => result == std::ops::ControlFlow::Break(Option::None),
                Option::Some(v) => result == std::ops::ControlFlow::Continue(v)
            };
        @*/
        //@ on_unwind_ens false;
    
    }
    
    impl<T> std::ops::FromResidual<std::option::Option<std::convert::Infallible>> for std::option::Option<T> {
    
        fn from_residual(residual: Option<std::convert::Infallible>) -> Option<T>;
        //@ req true;
        //@ ens result == Option::None;
        //@ on_unwind_ens false;
        
    }

}

mod result {

    enum Result<T, E> {
        Ok(T),
        Err(E),
    }
    
    impl<T, E> Result<T, E> {
    
        fn unwrap(self: Result<T, E>) -> T;
        //@ req thread_token(?t) &*& std::result::Result_own::<T, E>(t, self);
        //@ ens thread_token(t);
        //@ on_unwind_ens thread_token(t);
    
    }

}

mod vec {

    struct Vec<T, A>;
    
    //@ pred Vec<T, A>(self: Vec<T, A>, capacity: usize, elems: list<T>); // This predicate does *not* assert ownership of the elements.
    //@ pred Vec_minus_buffer<T, A>(self: Vec<T, A>, capacity: usize, len: usize, buffer: *T);
    
    /*@
    
    lem_auto Vec_inv<T, A>();
        req [?f]Vec::<T, A>(?vec, ?capacity, ?elems);
        ens [f]Vec::<T, A>(vec, capacity, elems) &*& length(elems) <= capacity &*& capacity <= isize::MAX;
    
    lem Vec_separate_buffer<T, A>(self: Vec<T, A>) -> *T;
        req [?f]Vec::<T, A>(self, ?capacity, ?elems);
        ens [f]Vec_minus_buffer::<T, A>(self, capacity, length(elems), result) &*& [f]result[..length(elems)] |-> elems &*& [f]result[length(elems)..capacity] |-> _;
    
    lem Vec_unseparate_buffer<T, A>(self: Vec<T, A>);
        req [?f]Vec_minus_buffer::<T, A>(self, ?capacity, ?len, ?buffer) &*& [f]buffer[..len] |-> ?elems &*& [f]buffer[len..capacity] |-> _;
        ens [f]Vec::<T, A>(self, capacity, elems);
    
    lem Vec_to_own<T, A>(self: Vec<T, A>);
        req thread_token(?t) &*& Vec::<T, A>(self, ?capacity, ?elems) &*& foreach(elems, own::<T>(t));
        ens thread_token(t) &*& <Vec<T, A>>.own(t, self);
    
    lem own_to_Vec<T, A>(self: Vec<T, A>);
        req thread_token(?t) &*& <Vec<T, A>>.own(t, self);
        ens thread_token(t) &*& Vec::<T, A>(self, ?capacity, ?elems) &*& foreach(elems, own::<T>(t));
    
    lem init_ref_Vec<T, A>(p: *Vec<T, A>);
        req ref_init_perm(p, ?x) &*& [?f](*x |-> ?v);
        ens ref_end_token(p, x, f/2) &*& [f/2](*x |-> v) &*& [f/2](*p |-> v) &*& ref_initialized(p);
    
    lem end_ref_Vec<T, A>(p: *Vec<T, A>);
        req ref_end_token(p, ?x, ?f) &*& [f](*p |-> ?v) &*& ref_initialized(p);
        ens [f](*x |-> v);
    
    @*/
    
    impl<T> Vec<T> {
    
        fn new() -> Vec<T, std::alloc::Global>;
        //@ req true;
        //@ ens Vec(result, _, []);
        //@ on_unwind_ens false;
    
    }
    
    impl<T, A> Vec<T, A> {
    
        fn len<'a>(self: &'a Vec<T, A>) -> usize;
        //@ req [?f](*self |-> ?self_) &*& [?fv]Vec::<T, A>(self_, ?capacity, ?elems);
        //@ ens [f](*self |-> self_) &*& [fv]Vec::<T, A>(self_, capacity, elems) &*& result == length(elems);
        //@ on_unwind_ens false;
    
        fn push<'a>(self: &'a Vec<T, A>, elem: T);
        //@ req thread_token(?t) &*& *self |-> ?self0 &*& Vec::<T, A>(self0, _, ?elems0) &*& drop_perm::<T>(?charged, ?R, t, elem);
        //@ ens thread_token(t) &*& *self |-> ?self1 &*& Vec::<T, A>(self1, _, append(elems0, [elem])) &*& drop_perm::<T>(charged, R, t, elem);
        //@ on_unwind_ens thread_token(t) &*& *self |-> ?self1 &*& Vec::<T, A>(self1, _, elems0);
        
        fn reserve<'a>(self: &'a Vec<T, A>, additional: usize);
        //@ req *self |-> ?self0 &*& Vec::<T, A>(self0, _, ?elems);
        //@ ens *self |-> ?self1 &*& Vec::<T, A>(self1, ?capacity, elems) &*& length(elems) + additional <= capacity;
        //@ on_unwind_ens *self |-> ?self1 &*& Vec::<T, A>(self1, _, elems);
        
        fn as_mut_ptr<'a>(self: &'a Vec<T, A>) -> *mut T;
        //@ req [?f](*self |-> ?self_) &*& [f]Vec_minus_buffer::<T, A>(self_, ?capacity, ?len, ?buffer);
        //@ ens [f](*self |-> self_) &*& [f]Vec_minus_buffer::<T, A>(self_, capacity, len, buffer) &*& result == buffer;
        //@ on_unwind_ens false;
        
        fn as_ptr<'a>(self: &'a Vec<T, A>) -> *const T;
        //@ req [?f](*self |-> ?self_) &*& [f]Vec_minus_buffer::<T, A>(self_, ?capacity, ?len, ?buffer);
        //@ ens [f](*self |-> self_) &*& [f]Vec_minus_buffer::<T, A>(self_, capacity, len, buffer) &*& result == buffer;
        //@ on_unwind_ens false;

        fn spare_capacity_mut<'a>(self: &'a Vec<T, A>) -> &'a [T];
        //@ req [?f](*self |-> ?self_) &*& [f]Vec_minus_buffer::<T, A>(self_, ?capacity, ?len, ?buffer);
        //@ ens [f](*self |-> self_) &*& [f]Vec_minus_buffer::<T, A>(self_, capacity, len, buffer) &*& result.ptr == buffer + len &*& result.len == capacity - len;
        //@ on_unwind_ens false;

        fn set_len<'a>(self: &'a Vec<T, A>, new_len: usize);
        //@ req *self |-> ?self0 &*& Vec_minus_buffer::<T, A>(self0, ?capacity, ?len, ?buffer) &*& new_len <= capacity;
        //@ ens *self |-> ?self1 &*& Vec_minus_buffer::<T, A>(self1, capacity, new_len, buffer);
        //@ on_unwind_ens false;
        
    }
    
}

mod io {

    struct Error;
    
    type Result<T> = std::result::Result<T, Error>;
    
    trait Write {
    
        fn write<'a, 'b>(self: &'a Self, buf: &'b [u8]) -> Result<usize>;
        //@ req thread_token(?t) &*& *self |-> ?self0 &*& <Self>.own(t, self0) &*& [?f]buf.ptr[..buf.len] |-> ?bs;
        //@ ens thread_token(t) &*& *self |-> ?self1 &*& <Self>.own(t, self1) &*& [f]buf.ptr[..buf.len] |-> bs &*& std::result::Result_own::<usize, Error>(t, result);
        //@ on_unwind_ens thread_token(t) &*& *self |-> ?self1 &*& <Self>.own(t, self1) &*& [f]buf.ptr[..buf.len] |-> _;
        
        fn flush<'a>(self: &'a Self) -> Result<()>;
        //@ req thread_token(?t) &*& *self |-> ?self0 &*& <Self>.own(t, self0);
        //@ ens thread_token(t) &*& *self |-> ?self1 &*& <Self>.own(t, self1);
        //@ on_unwind_ens thread_token(t) &*& *self |-> ?self1 &*& <Self>.own(t, self1);
        
    }

    struct Stdout;
    
    fn stdout() -> Stdout;
    //@ req thread_token(?t);
    //@ ens thread_token(t) &*& <Stdout>.own(t, result);
    //@ on_unwind_ens thread_token(t);

}

mod sync {
    mod atomic {

        enum Ordering {
            Relaxed,
            SeqCst
        }

        struct AtomicUsize;

        /*@
        
        lem_auto size_of_AtomicUsize();
            req true;
            ens std::mem::size_of::<AtomicUsize>() == std::mem::size_of::<usize>();
        
        lem_auto align_of_AtomicUsize();
            req true;
            ens std::mem::align_of::<AtomicUsize>() == std::mem::size_of::<usize>();
        
        fix AtomicUsize_inner(v: AtomicUsize) -> usize;
        pred AtomicUsize(p: *AtomicUsize; v: usize) = *p |-> ?v_ &*& v == AtomicUsize_inner(v_);
        
        lem AtomicUsize_to_usize(p: *AtomicUsize);
            req *p |-> ?v;
            ens *(p as *usize) |-> AtomicUsize_inner(v) &*& (p as usize) % std::mem::size_of::<usize>() == 0;

        lem usize_to_AtomicUsize(p: *usize);
            nonghost_callers_only
            req *p |-> ?v0 &*& (p as usize) % std::mem::size_of::<usize>() == 0;
            ens AtomicUsize(p as *AtomicUsize, v0);

        lem_type AtomicUsize_fetch_add_op(self: *AtomicUsize, val: usize, P: pred(), Q: pred(usize)) = lem();
            req AtomicUsize(self, ?v0) &*& P();
            ens AtomicUsize(self, (v0 + val) % (usize::MAX + 1)) &*& Q(v0);

        lem_type AtomicUsize_fetch_add_ghop(self: *AtomicUsize, val: usize, pre: pred(), post: pred(usize)) = lem();
            req atomic_mask(MaskTop) &*& is_AtomicUsize_fetch_add_op(?op, self, val, ?P, ?Q) &*& P() &*& pre();
            ens atomic_mask(MaskTop) &*& is_AtomicUsize_fetch_add_op(op, self, val, P, Q) &*& Q(?result) &*& post(result);

        lem_type AtomicUsize_fetch_sub_op(self: *AtomicUsize, val: usize, P: pred(), Q: pred(usize)) = lem();
            req AtomicUsize(self, ?v0) &*& P();
            ens AtomicUsize(self, (v0 - val + usize::MAX + 1) % (usize::MAX + 1)) &*& Q(v0);

        lem_type AtomicUsize_fetch_sub_ghop(self: *AtomicUsize, val: usize, pre: pred(), post: pred(usize)) = lem();
            req atomic_mask(MaskTop) &*& is_AtomicUsize_fetch_sub_op(?op, self, val, ?P, ?Q) &*& P() &*& pre();
            ens atomic_mask(MaskTop) &*& is_AtomicUsize_fetch_sub_op(op, self, val, P, Q) &*& Q(?result) &*& post(result);

        lem_type AtomicUsize_load_op(self: *AtomicUsize, P: pred(), Q: pred(usize)) = lem();
            req [?f]AtomicUsize(self, ?v) &*& P();
            ens [f]AtomicUsize(self, v) &*& Q(v);

        lem_type AtomicUsize_load_ghop(self: *AtomicUsize, pre: pred(), post: pred(usize)) = lem();
            req atomic_mask(MaskTop) &*& is_AtomicUsize_load_op(?op, self, ?P, ?Q) &*& P() &*& pre();
            ens atomic_mask(MaskTop) &*& is_AtomicUsize_load_op(op, self, P, Q) &*& Q(?result) &*& post(result);

        lem_type AtomicUsize_compare_exchange_op(self: *AtomicUsize, current: usize, new: usize, P: pred(), Q: pred(std::result::Result<usize, usize>)) = lem();
            req AtomicUsize(self, ?v0) &*& P();
            ens if v0 == current { AtomicUsize(self, new) &*& Q(std::result::Result::Ok(v0)) } else
                { AtomicUsize(self, v0) &*& Q(std::result::Result::Err(v0)) };

        lem_type AtomicUsize_compare_exchange_ghop(self: *AtomicUsize, current: usize, new: usize, pre: pred(), post: pred(std::result::Result<usize, usize>)) = lem();
            req atomic_mask(MaskTop) &*& is_AtomicUsize_compare_exchange_op(?op, self, current, new, ?P, ?Q) &*& P() &*& pre();
            ens atomic_mask(MaskTop) &*& is_AtomicUsize_compare_exchange_op(op, self, current, new, P, Q) &*& Q(?result) &*& post(result);
        
        @*/

        impl AtomicUsize {
            fn new(v: usize) -> AtomicUsize;
            //@ req true;
            //@ ens AtomicUsize_inner(result) == v;
            //@ on_unwind_ens false;

            fn from_ptr<'a>(ptr: *mut usize) -> &'a AtomicUsize;
            //@ req ptr as usize % std::mem::align_of::<AtomicUsize>() == 0;
            //@ ens result as *mut usize == ptr;
            //@ on_unwind_ens false;

            fn fetch_add<'a>(self: &'a AtomicUsize, val: usize, order: Ordering) -> usize;
            /*@
            req match order {
                    Ordering::Relaxed => false,
                    Ordering::SeqCst => is_AtomicUsize_fetch_add_ghop(?ghop, self, val, ?pre, ?post) &*& pre() &*& ens post(result) on_unwind_ens false,
                };
            @*/
            //@ ens true;
            //@ on_unwind_ens false;

            fn fetch_sub<'a>(self: &'a AtomicUsize, val: usize, order: Ordering) -> usize;
            //@ req order == std::sync::atomic::Ordering::SeqCst &*& is_AtomicUsize_fetch_sub_ghop(?ghop, self, val, ?pre, ?post) &*& pre();
            //@ ens post(result);
            //@ on_unwind_ens false;

            fn load<'a>(self: &'a AtomicUsize, order: Ordering) -> usize;
            //@ req order == std::sync::atomic::Ordering::SeqCst &*& is_AtomicUsize_load_ghop(?ghop, self, ?pre, ?post) &*& pre();
            //@ ens post(result);
            //@ on_unwind_ens false;

            fn compare_exchange<'a>(self: &'a AtomicUsize, current: usize, new: usize, success: Ordering, failure: Ordering) -> std::result::Result<usize, usize>;
            /*@ req success == std::sync::atomic::Ordering::SeqCst &*& failure == std::sync::atomic::Ordering::SeqCst &*&
                is_AtomicUsize_compare_exchange_ghop(?ghop, self, current, new, ?pre, ?post) &*& pre(); @*/
            //@ ens post(result);
            //@ on_unwind_ens false;
        }
    }
}

mod thread {

    struct JoinHandle<T>;
    
    fn sleep(duration: std::time::Duration);
    //@ req true;
    //@ ens true;
    //@ on_unwind_ens true;
    
}

mod time {

    struct Duration;
    
    impl Duration {
    
        fn from_millis(millis: u64) -> Duration;
        //@ req true;
        //@ ens true;
        //@ on_unwind_ens true;

    }
    
}

mod iter {

    trait Iterator {
        
        type Item;
        
        fn next<'a>(self: &'a mut Self) -> std::option::Option< <Self as std::iter::Iterator>::Item>;
        //@ req thread_token(?t) &*& *self |-> ?self0 &*& <Self>.own(t, self0);
        //@ ens thread_token(t) &*& *self |-> ?self1 &*& <Self>.own(t, self1) &*& <std::option::Option< <Self as std::iter::Iterator>::Item>>.own(t, result);
        //@ on_unwind_ens thread_token(t) &*& *self |-> ?self1 &*& <Self>.own(t, self1);
        
    }
    
}

mod fmt {

    struct Arguments<'a>;
    
    impl<'a> Arguments<'a> {
    
        fn new_const<N>(pieces: &'a [&'a str; N]) -> Arguments<'a>;
        //@ req thread_token(?t) &*& <&'a [&'a str; N]>.own(t, pieces);
        //@ ens thread_token(t) &*& <Arguments<'a>>.own(t, result);
        //@ on_unwind_ens thread_token(t);
    
    }

}

mod panicking {

    fn panic_fmt<'a>(args: std::fmt::Arguments<'a>);
    //@ req thread_token(?t) &*& <std::fmt::Arguments<'a>>.own(t, args);
    //@ ens false;
    //@ on_unwind_ens thread_token(t);

}

mod rt {

    fn panic_fmt<'a>(args: std::fmt::Arguments<'a>);
    //@ req thread_token(?t) &*& <std::fmt::Arguments<'a>>.own(t, args);
    //@ ens false;
    //@ on_unwind_ens thread_token(t);

}

mod convert {

    struct Infallible {}

}