/*@

abstract_type type_info;

@*/

mod ops {

    trait FnMut<Output, Args> {
    
        fn call_mut<'a>(self: &'a mut Self, args: Args) -> Output;
        //@ req thread_token(?t) &*& *self |-> ?self0 &*& <Self>.own(t, self0) &*& <Args>.own(t, args);
        //@ ens thread_token(t) &*& *self |-> ?self1 &*& <Self>.own(t, self1) &*& <Output>.own(t, result);
        
    }
    
}

mod rt {

    fn begin_panic<M>(msg: M); // Generated by the assert! macro
    //@ req true; // TODO: Express that the message is valid.
    //@ ens false;

}

mod num {

    /*@
    
    lem init_ref_usize(p: *usize, coef: real);
        req ref_init_perm::<usize>(p, ?x) &*& [?f](*x |-> ?v) &*& 0 < coef &*& coef < 1;
        ens ref_initialized(p) &*& [coef*f](*p |-> v) &*& [(1 - coef)*f](*x |-> v) &*& ref_end_token(p, x, coef*f);
    
    lem end_ref_usize(p: *usize);
        req ref_initialized(p) &*& ref_end_token(p, ?x, ?f) &*& [f](*p |-> ?v);
        ens [f](*x |-> v);
    
    @*/

    impl usize {
    
        fn checked_sub(self: usize, other: usize) -> std::option::Option<usize>;
        //@ req true;
        //@ ens if self < other { result == std::option::Option::None } else { result == std::option::Option::Some(self - other) };
        
    }

}

mod marker {

    struct PhantomData<T> {}
    
    /*@
    
    lem close_PhantomData_own<T>(t: thread_id_t, marker: PhantomData<T>);
        req true;
        ens <PhantomData<T>>.own(t, marker);
    
    lem close_ref_initialized_PhantomData<T>(marker: *PhantomData<T>, f: real);
        req true;
        ens [f]ref_initialized::<PhantomData<T>>(marker);
    
    @*/
    
}

mod intrinsics {

    unsafe fn copy_nonoverlapping<T>(src: *mut T, dst: *mut T, count: usize);
    //@ req [?f]src[..count] |-> ?vs &*& dst[..count] |-> _;
    //@ ens [f]src[..count] |-> vs &*& dst[..count] |-> vs;

    unsafe fn ptr_offset_from<T>(ptr: *const T, base: *const T) -> isize;
    /*@
    req
        (ptr as pointer).provenance == (base as pointer).provenance &*&
        (ptr as usize - base as usize) % std::mem::size_of::<T>() == 0 &*&
        isize::MIN <= ptr as usize - base as usize &*& ptr as usize - base as usize <= isize::MAX;
    @*/
    //@ ens result == ptr as usize - base as usize;
}

mod mem {

    //@ fix size_of_<T>() -> usize { std::mem::size_of::<T>() }
    //@ fix align_of_<T>() -> usize { std::mem::align_of::<T>() }

    fn size_of<T>() -> usize;
    //@ req true;
    //@ ens result == std::mem::size_of_::<T>();
    
    fn align_of<T>() -> usize;
    //@ req true;
    //@ ens result == std::mem::align_of_::<T>();

    fn drop<T>(value: T);
    //@ req thread_token(?t) &*& <T>.own(t, value);
    //@ ens thread_token(t);
    
    fn forget<T>(value: T);
    //@ req thread_token(?t) &*& <T>.own(t, value);
    //@ ens thread_token(t);
    
    fn replace<T, 'a>(dest: &'a mut T, src: T) -> T;
    //@ req *dest |-> ?v;
    //@ ens *dest |-> src &*& result == v;
    
    mod verifast {
    
        fn unfreeze<T>(ptr: *T);
        //@ req [1/2](*ptr |-> ?v);
        //@ ens *ptr |-> v;
        
        fn freeze<T>(ptr: *T);
        //@ req *ptr |-> _;
        //@ ens [1/2](*ptr |-> _);
    
    }
    
}

mod ptr {

    unsafe fn drop_in_place<T>(to_drop: *mut T);
    //@ req thread_token(?t) &*& *to_drop |-> ?v &*& <T>.own(t, v);
    //@ ens thread_token(t) &*& *to_drop |-> _;

    struct NonNull<T>;
    
    /*@
    
    lem close_NonNull_own<T>(t: thread_id_t, v: NonNull<T>);
        req true;
        ens (NonNull_own::<T>())(t, v);
        
    lem open_NonNull_own<T>(t: thread_id_t, v: NonNull<T>);
        req [_](NonNull_own::<T>())(t, v);
        ens NonNull_ptr(v) as usize != 0;
        
    fix NonNull_ptr<_T>(v: NonNull<_T>) -> *_T;
    
    lem NonNull_upcast<T0, T1>(v: NonNull<T0>);
        req true;
        ens NonNull_ptr::<T1>(upcast(v)) == NonNull_ptr::<T0>(v) as *_;
    
    lem init_ref_NonNull<T>(p: *NonNull<T>, coef: real);
        req ref_init_perm(p, ?x) &*& [?f](*x |-> ?v) &*& 0 < coef &*& coef < 1;
        ens ref_initialized(p) &*& [(1 - coef)*f](*x |-> v) &*& [coef*f](*p |-> v) &*& ref_end_token(p, x, coef*f);
    
    lem end_ref_NonNull<T>(p: *NonNull<T>);
        req ref_initialized(p) &*& ref_end_token(p, ?x, ?f) &*& [f](*p |-> ?v);
        ens [f](*x |-> v);
    
    @*/

    impl<T> NonNull<T> {
        //TODO: Needs support in MIR translator
        //fn from<'a>(reference: &'a mut T) -> NonNull<T>;
        // req thread_token(?t) &*& [?qa]lifetime_token(?a) &*& full_borrow(a, <T>.full_borrow_content(t, reference));
        // ens thread_token(t) &*& [qa]lifetime_token(a) &*& NonNull_own::<T>(t, result) &*& NonNull_ptr(result) == reference;

        unsafe fn new_unchecked(ptr: *mut T) -> NonNull<T>;
        //@ req ptr as usize != 0;
        //@ ens NonNull_ptr(result) == ptr;
        
        unsafe fn as_mut<'a, 'b>(self: &'b mut NonNull<T>) -> &'a mut T;
        //@ req *self |-> ?v;
        //@ ens *self |-> v &*& result == NonNull_ptr(v);

        unsafe fn as_ref<'a, 'b>(self: &'b NonNull<T>) -> &'a T;
        //@ req [?q](*self) |-> ?v;
        //@ ens [q](*self) |-> v &*& result == NonNull_ptr(v);

        fn as_ptr(self: NonNull<T>) -> *mut T;
        //@ req true;
        //@ ens result == NonNull_ptr(self);
    }
}

mod alloc {

    struct Layout;
    //@ fix Layout::size_(layout: Layout) -> usize;
    //@ fix Layout::align_(layout: Layout) -> usize;
    //@ fix Layout::from_size_align_(size: usize, align: usize) -> Layout;
    //@ fix Layout::new_<T>() -> Layout { Layout::from_size_align_(std::mem::size_of_::<T>(), std::mem::align_of_::<T>()) }
    
    /*@
    
    lem_auto Layout_size__Layout_from_size_align_(size: usize, align: usize);
        req true;
        ens Layout::size_(Layout::from_size_align_(size, align)) == size;
    
    lem_auto Layout_align__Layout_from_size_align_(size: usize, align: usize);
        req true;
        ens Layout::align_(Layout::from_size_align_(size, align)) == align;
    
    @*/
    
    impl Layout {
    
        fn new<T>() -> Layout;
        //@ req true;
        //@ ens result == Layout::new_::<T>();

        fn from_size_align_unchecked(size: usize, align: usize) -> Layout;
        //@ req is_power_of_2(align) == true && size <= isize::MAX - isize::MAX % align;
        //@ ens result == Layout::from_size_align_(size, align);

    }
    
    //@ pred alloc_block(ptr: *u8; layout: Layout);
    //@ pred alloc_block_in(alloc_id: any, ptr: *u8, layout: Layout;);
    
    /*@
    
    lem alloc_aligned(ptr: *mut u8);
        req [?f]alloc_block(ptr, ?layout);
        ens [f]alloc_block(ptr, layout) &*& (ptr as usize) % Layout::align_(layout) == 0;
    
    @*/
    
    /*@
    
    pred Allocator<A>(t: thread_id_t, alloc: A, alloc_id: any);
    
    lem Allocator_upcast<A0, A1>(alloc: A0);
        req Allocator::<A0>(?t, alloc, ?alloc_id) &*& is_subtype_of::<A0, A1>() == true;
        ens Allocator::<A1>(t, upcast(alloc), alloc_id);
    
    lem Allocator_send<A>(t1: thread_id_t, alloc: A);
        req Allocator::<A>(?t0, alloc, ?alloc_id) &*& is_Send(typeid(A)) == true;
        ens Allocator::<A>(t1, alloc, alloc_id);
    
    lem Allocator_to_own<A>(alloc: A);
        req Allocator::<A>(?t, alloc, _);
        ens <A>.own(t, alloc);
    
    lem open_Allocator_own<A>(alloc: A);
        req <A>.own(?t, alloc);
        ens Allocator::<A>(t, alloc, _);
    
    fix Allocator_full_borrow_content_<A>(t: thread_id_t, l: *A, alloc_id: any) -> pred();
    
    lem close_Allocator_full_borrow_content_<A>(t: thread_id_t, l: *A);
        req *l |-> ?alloc &*& Allocator::<A>(t, alloc, ?alloc_id);
        ens (Allocator_full_borrow_content_::<A>(t, l, alloc_id))();
    
    lem open_Allocator_full_borrow_content_<A>(t: thread_id_t, l: *A, alloc_id: any);
        req (Allocator_full_borrow_content_::<A>(t, l, alloc_id))();
        ens *l |-> ?alloc &*& Allocator::<A>(t, alloc, alloc_id);
    
    lem share_Allocator_full_borrow_content_<A>(k: lifetime_t, t: thread_id_t, l: *A, alloc_id: any);
        req type_interp::<A>() &*& atomic_mask(Nlft) &*& full_borrow(k, Allocator_full_borrow_content_::<A>(t, l, alloc_id)) &*& [?q]lifetime_token(k);
        ens type_interp::<A>() &*& atomic_mask(Nlft) &*& [_](<A>.share(k, t, l)) &*& [q]lifetime_token(k);
    
    pred share_allocator_end_token<A>(l: *A, alloc_id: any);
    
    lem share_allocator<'a, A>(l: *A);
        req *l |-> ?alloc &*& Allocator(?t, alloc, ?alloc_id);
        ens Allocator::<&'a A>(t, l, alloc_id) &*& share_allocator_end_token(l, alloc_id);
    
    lem end_share_allocator<'a, A>();
        req share_allocator_end_token::<A>(?l, ?alloc_id) &*& Allocator::<&'a A>(?t, _, alloc_id);
        ens *l |-> ?alloc &*& Allocator::<A>(t, alloc, alloc_id);
    
    pred ref_Allocator_end_token<A>(p: *A, x: *A, alloc_id: any);
    
    lem init_ref_Allocator<'a, A>(p: *A);
        req ref_init_perm(p, ?x) &*& *x |-> ?alloc &*& Allocator(?t, alloc, ?alloc_id);
        ens ref_initialized(p) &*& Allocator::<&'a A>(t, p, alloc_id) &*& ref_Allocator_end_token(p, x, alloc_id);
    
    lem end_ref_Allocator<'a, A>();
        req ref_Allocator_end_token::<A>(?p, ?x, ?alloc_id) &*& ref_initialized(p) &*& Allocator::<&'a A>(?t, _, alloc_id);
        ens *x |-> ?alloc &*& Allocator::<A>(t, alloc, alloc_id);
    
    pred share_allocator_at_lifetime_end_token<A>(t: thread_id_t, l: *A, alloc_id: any, k: lifetime_t);
    
    lem share_allocator_at_lifetime<'a, A>(l: *A);
        nonghost_callers_only
        req *l |-> ?alloc &*& Allocator(?t, alloc, ?alloc_id);
        ens Allocator::<&'a A>(t, l, alloc_id) &*& share_allocator_at_lifetime_end_token(t, l, alloc_id, 'a);
    
    lem end_share_allocator_at_lifetime<A>();
        nonghost_callers_only
        req share_allocator_at_lifetime_end_token::<A>(?t, ?l, ?alloc_id, ?k) &*& [_]lifetime_dead_token(k);
        ens *l |-> ?alloc &*& Allocator::<A>(t, alloc, alloc_id);
    
    pred ref_Allocator_end_token_at_lifetime<A>(t: thread_id_t, p: *A, x: *A, alloc_id: any, k: lifetime_t);
    
    lem init_ref_Allocator_at_lifetime<'a, A>(p: *A);
        nonghost_callers_only
        req ref_init_perm(p, ?x) &*& *x |-> ?alloc &*& Allocator(?t, alloc, ?alloc_id);
        ens ref_initialized(p) &*& Allocator::<&'a A>(t, p, alloc_id) &*& ref_Allocator_end_token_at_lifetime(t, p, x, alloc_id, 'a);
    
    lem end_ref_Allocator_at_lifetime<A>();
        nonghost_callers_only
        req ref_Allocator_end_token_at_lifetime::<A>(?t, ?p, ?x, ?alloc_id, ?k) &*& [_]lifetime_dead_token(k) &*& ref_initialized(p);
        ens *x |-> ?alloc &*& Allocator::<A>(t, alloc, alloc_id);
    
    @*/

    fn alloc(layout: Layout) -> *u8;
    //@ req 1 <= Layout::size_(layout);
    /*@
    ens
        if result == 0 {
            true
        } else {
            result[..Layout::size_(layout)] |-> _ &*& alloc_block(result, layout) &*&
            result as usize % Layout::align_(layout) == 0 &*&
            object_pointer_within_limits(result, Layout::size_(layout)) == true
        };
    @*/
    //@ terminates;
    
    fn realloc(buffer: *u8, layout: Layout, new_size: usize) -> *u8;
    //@ req buffer[..?len] |-> ?vs1 &*& buffer[len..Layout::size_(layout)] |-?-> ?vs2 &*& alloc_block(buffer, layout) &*& Layout::size_(layout) <= new_size;
    /*@
    ens
        if result == 0 {
            buffer[..len] |-> vs1 &*& buffer[len..Layout::size_(layout)] |-?-> vs2 &*& alloc_block(buffer, layout)
        } else {
            result[..len] |-> vs1 &*& result[len..Layout::size_(layout)] |-?-> vs2 &*&
            result[Layout::size_(layout)..new_size] |-> _ &*& alloc_block(result, Layout::from_size_align_(new_size, Layout::align_(layout)))
        };
    @*/
    
    fn dealloc(p: *u8, layout: Layout);
    //@ req alloc_block(p, layout) &*& p[..Layout::size_(layout)] |-> _;
    //@ ens true;
    //@ terminates;

    fn handle_alloc_error(layout: Layout);
    //@ req true;
    //@ ens false;
    //@ terminates;
    
    struct Global {}
    
    /*@
    
    fix Global_alloc_id() -> any;
    
    lem produce_Allocator_Global(t: thread_id_t);
        req true;
        ens Allocator(t, Global {}, Global_alloc_id);
    
    @*/
    
}

mod boxed {

    struct Box<T, A>;
    
    /*@
    
    pred Box<T>(self: Box<T, std::alloc::Global>, value: T);
    
    lem Box_to_own<T>(self: Box<T, std::alloc::Global>);
        req thread_token(?t) &*& Box::<T>(self, ?value) &*& <T>.own(t, value);
        ens thread_token(t) &*& <Box<T, std::alloc::Global>>.own(t, self);
    
    pred Box_in<T, A>(t: thread_id_t, self: Box<T, A>, alloc_id: any, value: T);
    
    lem Box_in_to_own<T, A>(self: Box<T, A>);
        req Box_in::<T, A>(?t, self, ?alloc_id, ?value) &*& <T>.own(t, value);
        ens <Box<T, A>>.own(t, self);
    
    @*/

    impl<T> Box<T> {
    
        fn new(x: T) -> Box<T, std::alloc::Global>;
        //@ req true;
        //@ ens Box(result, x);
        
        fn from_raw(x: *T) -> Box<T, std::alloc::Global>;
        //@ req *x |-> ?value &*& std::alloc::alloc_block(x as *u8, std::alloc::Layout::new_::<T>());
        //@ ens Box(result, value);
        
    }
    
    impl<T, A> Box<T, A> {
    
        fn new_in(x: T, alloc: A) -> Box<T, A>;
        //@ req thread_token(?t) &*& std::alloc::Allocator(t, alloc, ?alloc_id);
        //@ ens thread_token(t) &*& Box_in(t, result, alloc_id, x);
        
        fn from_raw_in(x: *T, alloc: A) -> Box<T, A>;
        //@ req *x |-> ?value &*& std::alloc::Allocator(?t, alloc, ?alloc_id) &*& std::alloc::alloc_block_in(alloc_id, x as *u8, std::alloc::Layout::new_::<T>());
        //@ ens Box_in(t, result, alloc_id, value);
    
        fn into_raw(b: Box<T, std::alloc::Global>) -> *T;
        //@ req Box(b, ?value);
        //@ ens *result |-> value &*& std::alloc::alloc_block(result as *u8, std::alloc::Layout::new_::<T>()) &*& result as usize != 0;
        
        fn into_inner(b: Box<T, A>) -> T;
        //@ req thread_token(?t) &*& Box_in::<T, A>(t, b, ?alloc_id, ?value);
        //@ ens thread_token(t) &*& std::alloc::Allocator::<A>(t, _, alloc_id) &*& result == value;
    
        fn leak<'a>(b: Box<T, A>) -> &'a mut T;
        //@ req Box_in::<T, A>(?t, b, ?alloc_id, ?value);
        //@ ens *result |-> value &*& std::alloc::alloc_block_in(alloc_id, result as *u8, std::alloc::Layout::new_::<T>()) &*& result as *_ as usize != 0 &*& std::alloc::Allocator::<A>(t, _, alloc_id);
    
    }

}

mod process {
    fn abort();
    //@ req true;
    //@ ens false;
    //@ terminates;

    fn exit(code: i32);
    //@ req true;
    //@ ens false;
    //@ terminates;
}
//Todo @Nima: Edit Rust parser so it substitutes `!` type with std_empty_ union

mod option {

    enum Option<T> {
        None,
        Some(T),
    }
    
    /*@
    
    fix Option_Some_0_offset<T>() -> usize;
    fix Option_Some_0_ptr<T>(ptr: *Option<T>) -> *T { field_ptr(ptr as pointer, typeid(T), Option_Some_0_offset::<T>()) as *T }
    
    pred Option_Some<T>(l: *Option<T>;); // Represents ownership of the discriminant
    
    lem open_points_to_Option_Some<T>(l: *Option<T>);
        req [?f](*l |-> Option::Some(?v0));
        ens [f]Option_Some(l) &*& [f](*Option_Some_0_ptr(l) |-> v0);
    
    lem close_points_to_Option_Some<T>(l: *Option<T>);
        req [?f]Option_Some(l) &*& [f](*Option_Some_0_ptr(l) |-> ?v0);
        ens [f](*l |-> Option::Some(v0));
    
    lem init_ref_Option_None<T>(p: *Option<T>, coef: real);
        req ref_init_perm::<Option<T>>(p, ?x) &*& [?f](*x |-> Option::None) &*& 0 < coef &*& coef < 1;
        ens ref_initialized::<Option<T>>(p) &*& ref_end_token(p, x, coef*f) &*& [(1-coef)*f](*x |-> Option::None) &*& [coef*f](*p |-> Option::None);
    
    pred init_ref_Option_Some_token<T>(p: *Option<T>, x: *Option<T>, frac: real);
    
    lem open_ref_init_perm_Option_Some<T>(p: *Option<T>);
        req ref_init_perm::<Option<T>>(p, ?x) &*& [?f]Option_Some::<T>(x);
        ens init_ref_Option_Some_token::<T>(p, x, f) &*& ref_init_perm::<T>(Option_Some_0_ptr(p), Option_Some_0_ptr(x));
    
    lem init_ref_Option_Some<T>(p: *Option<T>, coef: real);
        req init_ref_Option_Some_token::<T>(p, ?x, ?f) &*& ref_initialized::<T>(Option_Some_0_ptr(p)) &*& 0 < coef &*& coef < 1;
        ens ref_initialized::<Option<T>>(p) &*& [(1-coef)*f]Option_Some::<T>(x) &*& [coef*f]Option_Some::<T>(p) &*& ref_end_token(p, x, coef*f);
    
    lem end_ref_Option_None<T>(p: *Option<T>);
        req ref_initialized::<Option<T>>(p) &*& ref_end_token(p, ?x, ?f) &*& [f](*p |-> Option::None);
        ens [f](*x |-> Option::None);
    
    lem end_ref_Option_Some<T>(p: *Option<T>);
        req ref_initialized::<Option<T>>(p) &*& ref_end_token(p, ?x, ?f) &*& [f]Option_Some::<T>(p);
        ens [f]Option_Some::<T>(x) &*& ref_initialized::<T>(Option_Some_0_ptr(p));
    
    @*/
    
    impl<T> Option<T> {
    
        fn is_some<'a>(self: &'a Option<T>) -> bool;
        //@ req [?f](*self |-> ?v);
        //@ ens [f](*self |-> v) &*& result == (v != Option::None);
        
        fn take<'a>(self: &'a mut Option<T>) -> Option<T>;
        //@ req *self |-> ?v;
        //@ ens *self |-> Option::None &*& result == v;
        
        fn unwrap_or(self: Option<T>, default: T) -> T;
        //@ req true;
        //@ ens result == match self { Option::None => default, Option::Some(v) => v };
        
        fn unwrap_unchecked(self: Option<T>) -> T;
        //@ req self == Option::Some(?v);
        //@ ens result == v;
        
    }

}

mod result {

    enum Result<T, E> {
        Ok(T),
        Err(E),
    }
    
    impl<T, E> Result<T, E> {
    
        fn unwrap(self: Result<T, E>) -> T;
        //@ req thread_token(?t) &*& std::result::Result_own::<T, E>(t, self); // FIXME: For unwind safety, I think this needs to take a lifetime_token at a lifetime that is outlived by E.
        //@ ens thread_token(t);
    
    }

}

mod vec {

    struct Vec<T, A>;
    
    //@ pred Vec<T, A>(self: Vec<T, A>, capacity: usize, elems: list<T>); // This predicate does *not* assert ownership of the elements.
    //@ pred Vec_minus_buffer<T, A>(self: Vec<T, A>, capacity: usize, len: usize, buffer: *T);
    
    /*@
    
    lem_auto Vec_inv<T, A>();
        req [?f]Vec::<T, A>(?vec, ?capacity, ?elems);
        ens [f]Vec::<T, A>(vec, capacity, elems) &*& length(elems) <= capacity &*& capacity <= isize::MAX;
    
    lem Vec_separate_buffer<T, A>(self: Vec<T, A>) -> *T;
        req [?f]Vec::<T, A>(self, ?capacity, ?elems);
        ens [f]Vec_minus_buffer::<T, A>(self, capacity, length(elems), result) &*& [f]result[..length(elems)] |-> elems &*& [f]result[length(elems)..capacity] |-> _;
    
    lem Vec_unseparate_buffer<T, A>(self: Vec<T, A>);
        req [?f]Vec_minus_buffer::<T, A>(self, ?capacity, ?len, ?buffer) &*& [f]buffer[..len] |-> ?elems &*& [f]buffer[len..capacity] |-> _;
        ens [f]Vec::<T, A>(self, capacity, elems);
    
    lem Vec_to_own<T, A>(self: Vec<T, A>);
        req thread_token(?t) &*& Vec::<T, A>(self, ?capacity, ?elems) &*& foreach(elems, own::<T>(t));
        ens thread_token(t) &*& <Vec<T, A>>.own(t, self);
    
    @*/
    
    impl<T> Vec<T> {
    
        fn new() -> Vec<T, std::alloc::Global>;
        //@ req true;
        //@ ens Vec(result, _, []);
    
    }
    
    impl<T, A> Vec<T, A> {
    
        fn len<'a>(self: &'a Vec<T, A>) -> usize;
        //@ req [?f](*self |-> ?self_) &*& [f]Vec::<T, A>(self_, ?capacity, ?elems);
        //@ ens [f](*self |-> self_) &*& [f]Vec::<T, A>(self_, capacity, elems) &*& result == length(elems);
    
        fn push<'a>(self: &'a Vec<T, A>, elem: T);
        //@ req *self |-> ?self0 &*& Vec::<T, A>(self0, _, ?elems0);
        //@ ens *self |-> ?self1 &*& Vec::<T, A>(self1, _, append(elems0, [elem]));
        
        fn reserve<'a>(self: &'a Vec<T, A>, additional: usize);
        //@ req *self |-> ?self0 &*& Vec::<T, A>(self0, _, ?elems);
        //@ ens *self |-> ?self1 &*& Vec::<T, A>(self1, ?capacity, elems) &*& length(elems) + additional <= capacity;
        
        fn as_mut_ptr<'a>(self: &'a Vec<T, A>) -> *mut T;
        //@ req [?f](*self |-> ?self_) &*& [f]Vec_minus_buffer::<T, A>(self_, ?capacity, ?len, ?buffer);
        //@ ens [f](*self |-> self_) &*& [f]Vec_minus_buffer::<T, A>(self_, capacity, len, buffer) &*& result == buffer;
        
        fn as_ptr<'a>(self: &'a Vec<T, A>) -> *const T;
        //@ req [?f](*self |-> ?self_) &*& [f]Vec_minus_buffer::<T, A>(self_, ?capacity, ?len, ?buffer);
        //@ ens [f](*self |-> self_) &*& [f]Vec_minus_buffer::<T, A>(self_, capacity, len, buffer) &*& result == buffer;

        fn spare_capacity_mut<'a>(self: &'a Vec<T, A>) -> &'a [T];
        //@ req [?f](*self |-> ?self_) &*& [f]Vec_minus_buffer::<T, A>(self_, ?capacity, ?len, ?buffer);
        //@ ens [f](*self |-> self_) &*& [f]Vec_minus_buffer::<T, A>(self_, capacity, len, buffer) &*& result.ptr == buffer + len &*& result.len == capacity - len;

        fn set_len<'a>(self: &'a Vec<T, A>, new_len: usize);
        //@ req *self |-> ?self0 &*& Vec_minus_buffer::<T, A>(self0, ?capacity, ?len, ?buffer) &*& new_len <= capacity;
        //@ ens *self |-> ?self1 &*& Vec_minus_buffer::<T, A>(self1, capacity, new_len, buffer);
        
    }
    
}

mod io {

    struct Error;
    
    type Result<T> = std::result::Result<T, Error>;
    
    trait Write {
    
        fn write<'a, 'b>(self: &'a Self, buf: &'b [u8]) -> Result<usize>;
        //@ req thread_token(?t) &*& *self |-> ?self0 &*& <Self>.own(t, self0) &*& [?f]buf.ptr[..buf.len] |-> ?bs;
        //@ ens thread_token(t) &*& *self |-> ?self1 &*& <Self>.own(t, self1) &*& [f]buf.ptr[..buf.len] |-> bs &*& std::result::Result_own::<usize, Error>(t, result);
        
        fn flush<'a>(self: &'a Self) -> Result<()>;
        //@ req thread_token(?t) &*& *self |-> ?self0 &*& <Self>.own(t, self0);
        //@ ens thread_token(t) &*& *self |-> ?self1 &*& <Self>.own(t, self1);
        
    }

    struct Stdout;
    
    fn stdout() -> Stdout;
    //@ req thread_token(?t);
    //@ ens thread_token(t) &*& <Stdout>.own(t, result);

}

mod sync {
    mod atomic {

        enum Ordering {
            SeqCst
        }

        struct AtomicUsize;

        /*@
        
        lem_auto size_of_AtomicUsize();
            req true;
            ens std::mem::size_of::<AtomicUsize>() == std::mem::size_of::<usize>();
        
        lem_auto align_of_AtomicUsize();
            req true;
            ens std::mem::align_of::<AtomicUsize>() == std::mem::size_of::<usize>();
        
        fix AtomicUsize_inner(v: AtomicUsize) -> usize;
        pred AtomicUsize(p: *AtomicUsize; v: usize) = *p |-> ?v_ &*& v == AtomicUsize_inner(v_);
        
        lem AtomicUsize_to_usize(p: *AtomicUsize);
            req *p |-> ?v;
            ens *(p as *usize) |-> AtomicUsize_inner(v) &*& (p as usize) % std::mem::size_of::<usize>() == 0;

        lem usize_to_AtomicUsize(p: *usize);
            nonghost_callers_only
            req *p |-> ?v0 &*& (p as usize) % std::mem::size_of::<usize>() == 0;
            ens AtomicUsize(p as *AtomicUsize, v0);

        lem_type AtomicUsize_fetch_add_op(self: *AtomicUsize, val: usize, P: pred(), Q: pred(usize)) = lem();
            req AtomicUsize(self, ?v0) &*& P();
            ens AtomicUsize(self, (v0 + val) % (usize::MAX + 1)) &*& Q(v0);

        lem_type AtomicUsize_fetch_add_ghop(self: *AtomicUsize, val: usize, pre: pred(), post: pred(usize)) = lem();
            req atomic_mask(MaskTop) &*& is_AtomicUsize_fetch_add_op(?op, self, val, ?P, ?Q) &*& P() &*& pre();
            ens atomic_mask(MaskTop) &*& is_AtomicUsize_fetch_add_op(op, self, val, P, Q) &*& Q(?result) &*& post(result);

        lem_type AtomicUsize_fetch_sub_op(self: *AtomicUsize, val: usize, P: pred(), Q: pred(usize)) = lem();
            req AtomicUsize(self, ?v0) &*& P();
            ens AtomicUsize(self, (v0 - val + usize::MAX + 1) % (usize::MAX + 1)) &*& Q(v0);

        lem_type AtomicUsize_fetch_sub_ghop(self: *AtomicUsize, val: usize, pre: pred(), post: pred(usize)) = lem();
            req atomic_mask(MaskTop) &*& is_AtomicUsize_fetch_sub_op(?op, self, val, ?P, ?Q) &*& P() &*& pre();
            ens atomic_mask(MaskTop) &*& is_AtomicUsize_fetch_sub_op(op, self, val, P, Q) &*& Q(?result) &*& post(result);

        lem_type AtomicUsize_load_op(self: *AtomicUsize, P: pred(), Q: pred(usize)) = lem();
            req [?f]AtomicUsize(self, ?v) &*& P();
            ens [f]AtomicUsize(self, v) &*& Q(v);

        lem_type AtomicUsize_load_ghop(self: *AtomicUsize, pre: pred(), post: pred(usize)) = lem();
            req atomic_mask(MaskTop) &*& is_AtomicUsize_load_op(?op, self, ?P, ?Q) &*& P() &*& pre();
            ens atomic_mask(MaskTop) &*& is_AtomicUsize_load_op(op, self, P, Q) &*& Q(?result) &*& post(result);

        lem_type AtomicUsize_compare_exchange_op(self: *AtomicUsize, current: usize, new: usize, P: pred(), Q: pred(std::result::Result<usize, usize>)) = lem();
            req AtomicUsize(self, ?v0) &*& P();
            ens if v0 == current { AtomicUsize(self, new) &*& Q(std::result::Result::Ok(v0)) } else
                { AtomicUsize(self, v0) &*& Q(std::result::Result::Err(v0)) };

        lem_type AtomicUsize_compare_exchange_ghop(self: *AtomicUsize, current: usize, new: usize, pre: pred(), post: pred(std::result::Result<usize, usize>)) = lem();
            req atomic_mask(MaskTop) &*& is_AtomicUsize_compare_exchange_op(?op, self, current, new, ?P, ?Q) &*& P() &*& pre();
            ens atomic_mask(MaskTop) &*& is_AtomicUsize_compare_exchange_op(op, self, current, new, P, Q) &*& Q(?result) &*& post(result);
        
        @*/

        impl AtomicUsize {
            fn new(v: usize) -> AtomicUsize;
            //@ req true;
            //@ ens AtomicUsize_inner(result) == v;

            fn from_ptr<'a>(ptr: *mut usize) -> &'a AtomicUsize;
            //@ req ptr as usize % std::mem::align_of::<AtomicUsize>() == 0;
            //@ ens result as *mut usize == ptr;

            fn fetch_add<'a>(self: &'a AtomicUsize, val: usize, order: Ordering) -> usize;
            //@ req order == std::sync::atomic::Ordering::SeqCst &*& is_AtomicUsize_fetch_add_ghop(?ghop, self, val, ?pre, ?post) &*& pre();
            //@ ens post(result);

            fn fetch_sub<'a>(self: &'a AtomicUsize, val: usize, order: Ordering) -> usize;
            //@ req order == std::sync::atomic::Ordering::SeqCst &*& is_AtomicUsize_fetch_sub_ghop(?ghop, self, val, ?pre, ?post) &*& pre();
            //@ ens post(result);

            fn load<'a>(self: &'a AtomicUsize, order: Ordering) -> usize;
            //@ req order == std::sync::atomic::Ordering::SeqCst &*& is_AtomicUsize_load_ghop(?ghop, self, ?pre, ?post) &*& pre();
            //@ ens post(result);

            fn compare_exchange<'a>(self: &'a AtomicUsize, current: usize, new: usize, success: Ordering, failure: Ordering) -> std::result::Result<usize, usize>;
            /*@ req success == std::sync::atomic::Ordering::SeqCst &*& failure == std::sync::atomic::Ordering::SeqCst &*&
                is_AtomicUsize_compare_exchange_ghop(?ghop, self, current, new, ?pre, ?post) &*& pre(); @*/
            //@ ens post(result);
        }
    }
}